<head>
<meta charset=utf-8>
<title>Кратко о некоторых сортировках</title>
<meta name=keywords content="Linux Kernel,proc filesystem,system programming,sequential files,seq-file">
<style type=text/css>
pre, textarea {
    background-color: lightgreen;
}
table, th, td {
   border-width:thin;
   border-style:solid;
   border-color:green;
   border-spacing:0px;
}
</style>
</head>
<body>
<h1>Кратко о некоторых сортировках</h1>

<p>Рискну опять поднять эту тему. Начну со ссылки на статью Михаила Опанасенко <a href=https://habr.com/ru/post/335920/>Описание алгоритмов сортировки и сравнение их производительности</a>, очень впечатляющую по объёмам проделанной работы, а также по количеству приведеных ссылок. Свой материал начал готовить, не зная об этой публикации, что впоследствии, после ознакомления привело к необходимости его существенной переработки. Для тех, кто уже прочитал эту статью, сообщаю, что в моём материале, исследуются более разнообразные по типам данные, в частности, строки и вещественные числа, используются библиотеки boost и bsd, а также затрагиваются некоторые другие отсутствующие в статье Михаила темы. 

<p>Существуют десятки различных способов расположить элементы данных по-порядку. Среди них выделяют те, что работают быстро, такие, что, например, могут она в максимум за минуты отсортировать любой массив данных, размещенный в оперативной памяти компьютера. Более конкретно можно сказать, что сортировка, работающая быстро, упорядочивает на хорошем современном персональном компьютере миллиард целых чисел за менее, чем сто секунд. Если использовать для сортировки миллиарда или большего числа элементов примитивные, небыстрые методы, например, пузырьковую сортировку или сортировку выбором, то время, затраченное на такую обработку данных может превзойти любые ожидания &ndash; такой "процессинг" реально может занять несколько дней. Эта большая разница вызвана тем, что время сортировки быстрыми методами занимает величину примерно пропорциональную <i>N</i>log <i>N</i>, а примитивными &ndash; <i>N</i><sup>2</sup>. С ростом <i>N</i> разница между двумя величинами становится довольно большой. Поэтому примитивные методы разумно использовать только для работ с данными небольшого объёма, например, до тысяч элементов. Их также естественно использовать для обучения азам программирования, так как они существенно проще, чем быстрые методы.

<p>Хотелось бы разобраться в существующих в нынешних стандартных библиотеках методах сортировки. Выяснить как велика разница между ними по основной характеристике, скорости работы, а также их характерные особенности. Кроме того, рассмотрим попутно для сравнения и упражнения для ума некоторые несложные в реализации методы. Стоит ещё, отметить, что оптимизатор компилятора GCC и возможно других хороших компиляторов работает с сортировками очень хорошо, ускоряя код в несколько раз (иногда даже более 5 раз).

<p>Начнём с <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%BF%D1%83%D0%B7%D1%8B%D1%80%D1%8C%D0%BA%D0%BE%D0%BC>метода пузырька</a> (bubble sort) как самого простого и медленного. По этому методу нужно раз за разом проходить по массиву данных, сравнивая соседние элементы и меняя их местами, если порядок между ними нарушен. После каждого прохода, как минимум, один элемент (наибольший или наименьший &ndash; зависит от выбранного порядка) оказывается на своём месте. Помимо простоты у этого метода есть ещё одно достоинство, он не требует дополнительной памяти. Для тестов я использовал следующую <a href=https://github.com/litwr2/research-of-sorting/blob/master/bubble.cpp>реализацию</a>.

<p>Рассмотрим ещё один медленный метод &ndash; сортировку <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BE%D0%BC>выбором</a> (selection sort). Здесь на каждом проходе сначала находятся наибольший и наименьший элементы в данных и затем эти элементы ставятся в соответствующие выбранному порядку крайние позиции. На следующем проходе сортируем уже данные без этих крайних элементов. Этот метод также прост как и пузырьковая сортировка и также не требует дополнительной памяти, но он заметно быстрее. Более того, сортировка по этому методу выполняет рекордно минимальное количество перестановок элементов данных. Поэтому в случае, когда перестановки значительно медленнее сравнений, упорядочение методом выбора может оказаться наибыстрейшим, если число элементов данных не слишком велико. Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%B8%D1%80%D0%B0%D0%BC%D0%B8%D0%B4%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>кучей</a> (или пирамидальная), о которой речь пойдет далее, &ndash; это максимально продвинутый вариант рассмотриваемой сортировки. Вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/selection.cpp>реализация</a>.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%A8%D0%B5%D0%BB%D0%BB%D0%B0>Шелла</a> (shell sort) является самой простой среди быстрых методов и вполне пригодной для реализации только начинающими изучать программирование учащимися. Она является лишь некоторым видоизменением пузырьковой сортировки. Разница между ними только в том, что в сортирове Шелла расстояние между сравниваемыми элементами берётся меняющимся от прохода к проходу, от большего на первом проходе, до 1 на последних, таким образом, на этих последних проходах метод Шелла вырождается в примитивную сортировку пузырьком. Дональд Шелл опубликован базовый алгоритм сортировки, получившей его имя, в 1959 году. Таким образом, это одна из первых универсальных сортировок, которые работают быстро. Для сравнения, алгоритм быстрой сортировки был опубликован спустя два года, а популярные ныне сортировка Тима или интроспективная сортировка стали известны только в 90-е. Удивительно, но сортировка Шелла до сих пор является довольно плохо теоретически изученной: с ней связано несколько интересных нерешённых математических проблем, главная из которых &ndash; это как оптимально выбирать смещения между сравниваемыми элементами. Сначала для смещений широко использовались степени 2, потом стали использовать числа близкие к степеням 3. Постепенно обнаружились некоторые рекордные последовательности, например, <a href=https://oeis.org/A102549>A102549</a>. Такие последовательности находят путем колоссальных вычислений, поэтому они имеют очень небольшую длину, A102549 &ndash; это всего 8 элементов, что хватает только для данных до примерно из 3000 элементов. Для больших данных продолжения нужно искать почти наугад. Попробовал, например, использовать последовательность (см. <a href=https://github.com/litwr2/research-of-sorting/blob/master/shell.cpp>код</a> v2), из простых чисел, близких к степеням числа <i>e</i>, и получил на больших данных весьма неплохие по скорости результаты. Пробовал ещё продолжить A102549, домножая последний элемент на степени того же <i>е</i>, результаты для больших данных получились почти одинаковые с предыдущим случаем. Будет ли когда-нибудь найден способ находить оптимальные смещения? Возможно, но осмелюсь предположить, что не ранее, чем через 100 лет. Михаил Опанасенко также пытаелся разгадать сортировку Шелла и получил очень интересный результат о том, что смещения, выбираемые по формуле <i>s<sub>n+1</sub>=10s<sub>n</sub>/3</i> (реализацию см. в коде v3), дают очень хороший эффект и возможно даже, что близкий к идеальному. Вынужден признать, что предложенные выше табличные методы выбора смещения работают чуть (примено на 5%) медленнее. Попробовал брать простые числа, ближайшие к числам из приведённой последовательности, но это в среднем не улучшило результаты. Однако, при сортировке структур данных с ключом было выявлено, что эти табличные методы работают несколько быстрее (опять примерно до 5%), что можно объяснить тем, что они производят меньше перестановок. Интриги прибавляет факт, что сортировка v1 со смещениями, близкими к 3, на числах работает почти с той же скоростью, что и v2 и v3, но на строках заметно (более 100%!) медленнее. Этот результат очень необычен и показывает, что в сети можно найти такие варианты реализации сортировки Шелла, что со строками они будут работать квадратично, и даже заметно медленнее "пузырька"! Отклонения на совсем небольшую величину от хороших значений смещений может существенно ухудшить скорость работы. Сортировка Шелла используется в ядре Linux, а в некоторых библиотеках С её код используется для qsort.
 
<p><a href=https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>Быстрая</a> сортировка (quick sort) лишь незначительно сложнее алгоритма Шелла и до сих пор является одним из самым быстрым способом упорядочить случайно разбросанные данные. Однако у этой сортировки есть несколько недостатков. Ей требуется дополнительная память и для очень редких случаев она работает очень медленно, по квадратичной зависимости. Главная идея этого метода в разделении данных на две части: данные в одной части должны быть больше или меньше (зависит от выбранного порядка), чем в другой. Существует несколько способов такого разделения. В идеале при каждом делении обе части должны получаться примерно одинаковыми по размеру, а хуже всего получается тогда, когда при делении одна из частей получается состоящей только из одного элемента. Рассмотрим несколько <a href=https://github.com/litwr2/research-of-sorting/blob/master/qsort.cpp>реализаций</a> алгоритмов быстрой сортировки, в частности, метод Хоара, в котором опорный элемент выбирается из середины сортируемых данных.
В
<p>Рассмотрим ещё чрезвычайно компактный алгоритм Ломуто, который обычно применяет меньше сравнений, но больше перестановок, чем приведённый алгоритм Хоара. Таким образом, если данные сортируются по ключу, размер которого невелик по сравнению с размером всего элемента данных, алгоритм Ломуто менее предпочтительным рядом с рассмотренным выше. В частности, этот алгоритм показал себя очень плохо (100-200% медленнее) при сортировке больших массивов строк С++. Кроме того, среди рассмотренных вариантов быстрой сортировка эта оказалась почему-то при практических прогонах самой жадной к размеру стека: при сортировке 100 миллионов случайных С++ строк только этой сортировке не хватило стандартных для Линукса 8 мегабайт для стека, пришлось ставить через ulimit этот размер побольше. 

<p>Метод Ломуто в качестве опорного выбирает последний элемент, но возможно реализовать быструю сортировку вообще без опорного элемента (см. ).

<p>10 лет назад был опубликован алгоритм быстрой сортировки с двумя опорными точками, который стал стандартным для языка Java. Его автор &ndash; Владимир Ярославский. Действительно работает, как правило, очень быстро. Немного его оптимизировал, использовав давно известный факт, что на архитектуре x86, swap работает быстрее чем присваивание, а для строк С++ &nadsh; намного быстрее (shell 3n - too).

<p>Дополнительная память для быстрых сортировок нужна для организации рекурсивных вызовов. Однако, второй такой вызов можно заменить на цикл, проведя оптимизацию <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D1%8F>хвостовой рекурсии</a>, которая по скорости это даёт лишь совсем маленький выигрыш, но существенно снижает размер используемых дополнительных данных (для большего эффекта, согласно Седгевику, нужно делать рекурсивный вызов только для большей части данных). Кроме того, в системных программах можно проверять указатель стека и если он приблизился к критическому значению, то можно просто сбросить все рекурсивные вызовы и начать сортировку заново &ndash; для этого случая очевидно, что нужно использовать вариант быстрой сортировки, не замедляющейся на почти упорядоченных данных, например, предложенный выше вариант Хоара. Борьба с использованием дополнительной памяти может считаться главной идеей быстрой сортировки из стандартной библиотеки языка С. В ней вообще отказались от рекурсии! Вместо неё используют её симуляцию, что позволяет на треть сократить нагрузку на стек. Код получился немаленький, около 150 строк. Об этой сортировке ещё будет небольшой материал ниже.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B5%D1%88-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0>хэшем</a> (hash sort) теоретически может быть очень быстрой, близкой к &#x223d;<i>N</i>. Однако, иногда она может работать и по квадратичной зависимости. Скорость работы этого метода сортировки очень зависит от входных данных. Если данные равномерно распределяются хэш-функцией по вспомогательному массиву, то получаем максимально быструю линейную зависимость. А если все данные распределяются в один элемент массива, то получаем худшую зависимость типа &#x223d;<i>N</i><sup>2</sup>. Как и для сортировки деревом, для сортировки хэшем нужно довольно много дополнительных данных, в приводимом <a href=https://github.com/litwr2/research-of-sorting/blob/master/hash.cpp>листинге</a> кода нужно 12 дополнительных байт на каждый сортируемый элемент данных. Интересным свойством сортировки хэшем является отсутствие операций сравнения между элементами данных, что отличает эту сортировку от всех рассмотренных выше. Точнее эти операции нужны только для случая коллизий. При сортировке данных, где ключ совпадает со всем элементом данных, можно использовать дополнительный счетчик числа одинаковых элементов, но это это очень сомнительная оптимизация. Можно ещё использовать бинарное дерево вместо списка для хранения данных хэш-коллизий, это значительно ускоряет работу для отдельных частных случаев, когда много коллизий, но в целом работа при использовании бинарного дерева во многих случаях замедляется. Стандартный хэш С++ (unordered_multiset) для сортировки у меня приспособить не получилось: пробовал использовать монотонные хэш-функции и упорядочивающие отношения вместо равенства &ndash; это не сработало (листинг <a href=>тут</a>).

<p>Сортировка массивом (array sort) очень похожа на предыдущую. Также используется вспомогательный массив, куда хэш-функцией заносятся значения. При коллизии нужно сдвинуть непрерывный фрагмент занятых элементов на позицию влево или вправо, освобождая указываемую хэш-функцией позицию для нового элемента. Для получения хорошей скорости нужно, чтобы вспомогательный массив был в несколько раз (от 2-3) больше исходного. С ростом размера вспомогательного массива скорость работы увеличивается только до некоторого предела, зависящего от сортируемых данных и связанной с ними хэш-функции, а затем (типично с 4-5) падает. Скорость работы &ndash; примерно такая же как и у хэша, но хороших данных чуть быстрее, а на плохих &ndash; заметно медленнее. Этой сортировке также надо довольно много дополнительной памяти. Если ограничить количество элементов в сортируемом массиве числом чуть большим четырех миллиардов, то утроенный вспомогательный массив потребует столько же дополнительных данных, что и сортировка хэшем, а усемеренный &ndash; 28 байт, что заметно меньше, чем для сортировки деревом. В Википедии статьи про такой алгоритм нет, а вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/array.cpp>реализация</a>.

<p>Одна из самых быстрых сортировок, которая вообще не использующая сравнений, &ndash; это известная ещё с XIX века <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%80%D0%B0%D0%B7%D1%80%D1%8F%D0%B4%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>поразрядная сортировка</a> (radix sort). Её идея очень проста &ndash; нужно работать с группами разрядов представления данных (точнее, только ключа данных). По каждой группе строятся таблицы, а результаты потом сравнительно простым способом объединяют. Существует два основных способа использовать поразрядную сортировку. Для сортировки чисел разряды удобнее брать справа-налево, а для сортировки строк слева-направо. Поразрядная сортировка часто бывает значительно быстрее любых других методов упорядочения данных. Удивительно, что поддержка поразрядной сортировки до сих пор не слишком значительна: её нет ни в boost, ни в стандартной библиотеке С++, мне неизвестен даже её вариант для какой-нибудь известной библиотеки для работы с числами или строками С++. У этой сортировки есть, конечно, и недостатки. Например, ей требуется дополнительная память, чуть большая, чем для исходных данных (это существенно меньше, чем для сортировки хэшем или массивом и тем более деревом). Она также чувствительна к типу данных для сортировки, например, нужно иметь свой вариант такой сортировки для данных каждого размера. Кроме того, нужно делать специальный вариант для отрицательных целых чисел, а поддержка работы с вещественными числами может потребовать совсем немаленьких усилий. Эта сортировка может показать удивительно плохие результаты при работе с маленькими числовыми массивами, работая на несколько порядков медленнее, чем даже пузырьковая, хотя речь идет о величинах не более нескольких миллисекунд и эту разницу будет непросто заметить.

<p>Далее рассмотрим некоторые сортировоки, которые можно встретить в стандартых библиотеках: 

<ul>
<li>быструю из стандартной библиотеки C (qsort), о ней уже писал. Могу здесь только добавить, что это сортировка как и другие С-сортировки (например, следующие далее из библиотеки BSD) непригодны для работы с объектными данными, в частности, строками С++, что вызвано тем, что такие данные не являются <a href=https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85>POD</a>. Имея исходники, проблему легко решить, заменяя операции типа memcpy на обычные присваивания. Можно ещё заметить, что в некоторых стандартных библиотеках С, эта сортировка может быть не обязательно именно быстрой, её могут заменять на другие. В текущей версии для GCC эта сортировка даже обладает свойством устойчивости;

<li><a href=https://ru.wikipedia.org/wiki/Introsort>интроспективную</a> из стандартной библиотеки C++ (std::sort);

<li>устойчивую из стандартной библиотеки С++ (<a href=https://en.cppreference.com/w/cpp/algorithm/stable_sort>std::stable_sort</a>). Сортировка имеет свойство устойчивости, если она сохраняет относительный порядок между элементами с одинаковым ключом;

<li><a href=https://ru.wikipedia.org/wiki/Timsort>Тима</a> из <a href=https://github.com/gfx/cpp-TimSort>github-репозитория</a>, она является стандартной в языке питон;

<li>поразрядная из BSD библиотеки C (radixsort), там же есть устойчивый вариант этой сортировки (sradixsort). К сожалению, обе эти сортировки можно использовать только для С-строк. Как будет видно из данных по тестам &ndash; это сегодня набыстрейший способ отсортировать строки и поэтому удивительно, что нет её варианта стандартного для строк С++;

<li><a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC>слиянием</a> из BSD библиотеки C (mergesort). Эта сортировка известна как одна из самых быстрых для данных с последовательным доступом (файлы, списки) и возможно используется в стандартной библиотеке С++ для сортировки списков (std::list и std::forward_list). Кстати, эта она известна ещё с 1948 и одним из её разработчиков был небезизвестный фон Нейман;

<li><a href=https://ru.wikipedia.org/wiki/%D0%9A%D1%83%D1%87%D0%B0_(%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)>кучей</a> из BSD библиотеки C (heapsort);

<li>кучей из стандартной библиотеки C++. Такая сортировка делается за две операции: построение кучи (std::make_heap) и затем собственно сортировка (std::sort_heap);

<li>бинарным сбалансированным деревом (std::multiset) &ndash; просто заполняем дерево, а затем обходим. Можно считать этот метод нерекурсивной быстрой сортировкой. Некоторая проблема возникает в том, что стандартый распределитель памяти отличается заметной неспешностью, поэтому для лучших результатов надо использовать свой распределитель, что ускоряет примерно на 10-30%. Можно ещё отметить, что такой метод требует очень много дополнительной памяти, с g++ на каждый элемент данных, помимо него самого нужно ещё хранить 36 байт (на архитектуре x86-64);

<li><a href=https://en.wikipedia.org/wiki/Spreadsort>spreadsort</a> из библиотеки boost, изобретенный уже в 21 веке, наиболее быстрый на сегодня алгоритм из присутствующих в известных библиотеках. Эта сортировка использует некоторые идеи поразрядной и подобно ей может быть довольно капризной к типу аргументов. Только поразрядная сортировка может сегодня обогнать более универсальную spreadsort &ndash; за большую универсальность, как это обычно бывает, пришлось заплатить иногда весьма заметным замедлением работы. У этой сортировки обнаружилась очень неприятная проблема &mdash; при сортировке небольших (до 1000 элементов) массивов С-строк она работает с ошибками;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/pdqsort.html>pdqsort</a> из библиотеки boost, новый алгоритм, сочетающий в себе, как заявлено автором, лучшие черты быстрой сортировки и сортировки кучей. Это новый алгоритм, который пока ещё не описан в Википедии; 

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/spinsort.html>spinsort</a> из библиотеки boost. Это также новый алгоритм, который ещё не описан в Википедии;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/flat_stable_sort.html>flat_stable_sort</a> из библиотеки boost. Это ещё один новый алгоритм, который пока не описан в Википедии;

<p>Соберём основные сведения об этих сортировках в следующую таблицу. Красным выделены предполагаемые величины, их реальное значение может быть другим.

<div align=center>
<table border=1>
<tr><th rowspan=2>Алгоритм<th colspan=3>Время работы<th rowspan=2>Устойчивость<th rowspan=2>Дополнительная<br>память
<tr><th>наилучшее<th>среднее<th>наихудшее
<tr><td>radix<td colspan=3 align=center>&#x223d;<i>N</i><td align=center>***<td align=right>&#x223d;<i>N</i>
<tr><td>shell<td align=center>&#x223d;<i>N</i>log <i>N</i><td colspan=2 align=center>&#x223d;<i>N</i>(log <i>N</i>/log log <i>N</i>)<sup>2</sup><td align=center rowspan=3>нет<td align=right>0
<tr><td>quick<td colspan=2 align=center>&#x223d;<i>N</i>log <i>N</i><td align=center>&#x223d;<i>N</i><sup>2</sup><td align=right>&#x223d;log <i>N</i>*
<tr><td>std::sort<td colspan=3 align=center>&#x223d;<i>N</i>log <i>N</i><td align=right>&#x223d;log <i>N</i>
<tr><td>std::stable_sort<td colspan=2 align=center>&#x223d;<i>N</i>log <i>N</i><td align=center>&#x223d;<i>N</i>(log <i>N</i>)<sup>2</sup><td rowspan=2 align=center>еcть<td align=right>от 0 до <i>N</i>**
<tr><td>tim<td align=center rowspan=8>&#x223d;<i>N</i><td colspan=2 rowspan=5 align=center>&#x223d;<i>N</i>log <i>N</i><td align=right><i>N</i>
<tr><td>spread<td rowspan=2 align=center>нет<td align=right style=color:red>&#x223d;log <i>N</i>
<tr><td>pdq<td align=right>&#x223d;log <i>N</i>
<tr><td>spin<td rowspan=2 align=center>есть<td align=right><i>N</i>/2
<tr><td>flat_stable<td align=right><i>N</i>/256 + 8KB
<tr><td>hash<td align=center style=color:red rowspan=2>&#x223d;<i>N</i>log <i>N</i><td align=center rowspan=2>&#x223d;<i>N</i><sup>2</sup><td rowspan=5 align=center>нет<td align=right rowspan=2>&#x223d;<i>N</i>
<tr><td>array
<tr><td>bubble<td colspan=2 align=center>&#x223d;<i>N</i><sup>2</sup><td align=right rowspan=2>0
<tr><td>heap<td colspan=3 rowspan=3 align=center>&#x223d;<i>N</i>log <i>N</i>
<tr><td>tree<td align=right>&#x223d;<i>N</i>
<tr><td>merge<td align=center>***<td align=right><i>N</i>
<tr><td>selection<td colspan=3 align=center>&#x223d;<i>N</i><sup>2</sup><td align=center rowspan=4>нет<td align=right>0
</table>
<p>* &ndash; при использовании оптимизации хвостовой рекурсии по методу, предложенному Седгевиком (Sedgewick).
<p>** &ndash; при наличие дополнительной памяти производительность повышается.
<p>*** &ndash; зависит от реализации.
</div>

<p>Рассмотрим таблицу времени (в мс) работы этих алгоритмов на массиве случайных целых чисел (32-битных) на компьютере с 8 ГБ оперативной памяти с процессором AMD Phenom&#x2122; II X4 955 @3.214 МГц. Тайминги приводятся по среднему от пяти прогонов. Хотя из-за того, что многие современные процессоры работают, переключаясь между разными частотами, а также из-за особенностей работы с кешем, эти результаты в лучшем случае только приблизительны (могу предполагать что неточности таймингов могут доходить до 20%). На лучших современных процессорах для ПК результат может быть получен в 2-3 раза быстрее. Следует подчеркнуть, что это самый типичный случай заполнения массива, все остальные способы &ndash; это крайне редкие и даже почти невозможные при нормальной работе частности.

<div align=center>
<iframe src=table1.html height=452 width=615 scrolling=no style=border:none></iframe>
<p align=center>* &ndash; выведенное из формул, приблизительное значение
</div>

<p>Некоторые выводы по результатам этой таблицы:
<ul>
<li>стандартная сортировка библиотеки C относительно медленная, она уступает по скорости другим реализациям быстрой сортировки;
<li>std::stable_sort очень быстрая и (сюрприз!) значительно обгоняет даже назначенную быть более быстрой, неустойчивую std::sort;
<li>shellsort (e) на данных размером от 10 миллионов элементов и менее обгоняет timsort и даже некоторые быстрые сортировки;
<li>pdqsort работает несколько медленнее, чем и std::sort, что противоречит его заявленным свойствам;
<li>timsort уступала по скорости qsort (clib) вплоть до массива с миллиардом элементов, но на нём, как наверное и на больших данных, становится чуть быстрее;
<li>heapsort и особенно treesort заметно тормозят, но на фоне bubblesort или даже selectionsort видно, что это всё-таки быстрые методы. Интересно, что std::sort_heap на небольших данных обгоняет heapsort из BSD, но с ростом размера данных теряет преимущество и начинает уступать;
<li>hash_sort показала совершено посредственные результаты, это из-за того, что из-за использования дополнительной памяти резко падает эффективность работы кэшей процессора. На небольших случайных данных (менее ста тысяч элементов) сортировка хэшем обгоняет лучшие быстрые (qsort) сортировки;
<li>легко заметить, что у heapsort и treesort зависимости хотя и явно не квадратичные, но очевидно и не <i>N</i>log <i>N</i>, а существенно хуже &ndash; сравните с сортировкой Шелла, которая с ростом объёма данных ведёт себя гораздо лучше, чем heapsort или treesort, при том, что она сама медленнее, чем <i>N</i>log <i>N</i>. Таким образом, практические реализации heapsort и std::multiset не соответствуют их теоретическим спецификациям.
</ul>

<p>Рассмотрим ещё таблицу времени (в мс) работы этих же алгоритмов на массиве записей, состоящих из пяти целых чисел, из которых одно используется как ключ. Тайминги опять приводятся по среднему от пяти прогонов. При сортировке таких данных более существенно на время вычислений начинает влиять количество перестановок, поэтому методы с меньшим числом перестановок получают некоторое преимущество, которое растет с ростом размера данных, не используемых как ключ. 

<div align=center>
<iframe src=table2.html height=452 width=600 scrolling=no style=border:none></iframe>
<p align=center>* &ndash; выведенное из формулы, приблизительное значение
</div>

<p>Из результатов в этой таблице также можно сделать несколько выводов:
<ul>
<li>std::stable_sort при работе с такими данными показывает значительно худшую производительность;
<li>hash_sort обгоняет shellsort, но очевидно, что с небольшим приращением к объёму данных, shellsort станет быстрее, что показывает, что динамика скорости у сортировки хэшем существенно хуже логарифмической;
<li>интересно, что heapsort (bsd) и treesort на таких данных ведут себя практически идентично;
<li>qsort (Hoare) становится самой быстрой среди быстрых сортировок;
<li>pdqsort чуть обогнала на таких данных std::sort.
</ul>

<p>Рассмотрим теперь производительность сортировок на разного рода редких, крайних случаях. Используем массив целых чисел из 100 тысяч элементов, брать больше миллиона для таких тестов не рекомендую. Используются следующие типы заполнения:
<ol type=I>
<li>строго по возрастанию;
<li>строго по убыванию;
<li>случайные числа из диапазона от 0 до 99;
<li>случайная последовательность из 0 и 1;
<li>константой 0;
<li>последовательность, приводящая приведёный вариант qsort (Hoare) к самому медленному исполнению. Любопытно, что таких последовательностей ровно 2<sup><i>N</i>-3</sup> среди всех последовательностей длины <i>N</i>;
<li>строго по возрастанию, с вставкой 1% случайных чисел.
</ol>

<div align=center>
<iframe src=table3.html height=462 width=440 scrolling=no style=border:none></iframe>
</div>

<p>По этим результатам мои выводы следующие:
<ul>
<li>эти тесты обнаруживают слабые места быстрых сортировок. Однако выбор опорного элемента сложным образом делает вероятность попадания на плохую для сортировки последовательность практически нулевой. Можно также выбирать опорный элемент на каждом проходе по разному, случайно. Возможно так и делают в qsort (clib). Рассматриваемый метод Хоара работает медленно только на специально сконструированных последовательностях, встретить которую случайно при практической работе &ndash; это случай с вероятностью 2<sup><i>N</i>-3</sup>/<i>N</i><sup><i>N</i></sup>, то есть почти абсолютно невозможное событие. Варианты быстрых сортировок Ломуто и без опорного элемента показывают довольно плохие результаты как на частичично упорядоченных данных, так и на данных с маленьким разбросом значений;
<li>на некоторых частных случаях, самая медленная "пузырьковая" сортировка даёт отличные результаты, а самые быстрые qsort наоборот очень плохие;
<li>сортировка хэшем показала очень плохой результат на заполнении типа VII, это объясняется тем, что последовательность по возрастанию берётся из последовательных чисел, начиная с 0, а случайные числа из 1% берутся из диапазона от 0 до RAND_MAX, что скучивает все последовательные 99% данных в один элемент хэша. Этот случай очень хорошо демонстрирует проблемы, которые могут возникнуть при использовании этой сортировки с неизвестными данными;
<li>сортировка выбором ведёт себя очень стабильно на всех типах заполнения, heapsort и treesort также довольно стабильны, без явных пиков и провалов;
<li>поразительно плохой результат qsort (Lamuto) на заполнении типа VII был для меня неожиданностью. 
</ul>

<p>И в заключении рассмотрим результаты теста, где сортировки работают со всеми возможными последовательностями данных.  Число таких последовательностей равно факториалу от их длины, таким образом, для последовательностей длины 12 существует 479'001'600 вариантов &ndash; такое их количество хороший современный ПК обсчитает за менее, чем минуту. Если мы возьмём последовательности длины 14, то получим уже 87'178'291'200 вариантов на несколько часов работы компьютера. Поэтому в следующей таблице &ndash; среднее время (в нс) одной сортировки при сортировке всех перестановок длиной только 12. В качестве данных берутся прежние два варианта с целыми числами и записями из целых чисел. Конечно, результаты по таким маленьким данным не слишком репрезентативны и особенно по сложным методам сортировки, но некоторое представление о поведении сортировок они всё-таки дополняют. 
<br><br>

<div align=center>
<table border=1>
<tr><th rowspan=2>Ранг<th rowspan=2>Алгоритм<th colspan=2>Тайминги<th rowspan=2>Ранг
<tr><td align=right>4 байта<td align=right>4+16 байт
<tr><td align=center>7<td>shell (e)<td align=right>157<td align=right>220<td align=right>9
<tr><td align=center>14<td>qsort (clib)<td align=right>287<td align=right>434<td align=right>15
<tr><td align=center>11<td>qsort (Hoare)<td align=right>182<td align=right>196<td align=right>6
<tr><td align=center>8<td>qsort (no pivot)<td align=right>158<td align=right>204<td align=right>7
<tr><td align=center>6<td>qsort (Lomuto)<td align=right>154<td align=right>215<td align=right>8
<tr><td align=center>1<td>std::sort<td align=right>116<td align=right>165<td align=right>4
<tr><td align=center>10<td>std::stable_sort<td align=right>173<td align=right>289<td align=right>12
<tr><td align=center>9<td>timsort<td align=right>167<td align=right>236<td align=right>10
<tr><td align=center>17<td>heapsort (bsd)<td align=right>629<td align=right>1848<td align=right>17
<tr><td align=center>13<td>heapsort<td align=right>257<td align=right>370<td align=right>13
<tr><td align=center>4<td>spreadsort<td align=right>123<td align=right>155<td align=right>1
<tr><td align=center>2<td>pdqsort<td align=right>117<td align=right>156<td align=right>2
<tr><td align=center>3<td>spinsort<td align=right>119<td align=right>163<td align=right>3
<tr><td align=center>18<td>flat_stable_sort<td align=right>2239<td align=right>1165<td align=right>18
<tr><td align=center>15<td>hash_sort<td align=right>319<td align=right>446<td align=right>16
<tr><td align=center>16<td>tree_sort<td align=right>404<td align=right>432<td align=right>14
<tr><td align=center>12<td>bubble_sort<td align=right>194<td align=right>252<td align=right>11
<tr><td align=center>5<td>selection_sort<td align=right>151<td align=right>175<td align=right>5
</table>
</div>
<br>

<p>По последним результатам у меня получилось всего два комментария:
<ul>
<li>как и почти обычно heapsort выделяется своей неспешностью, а flat_stable_sort показала просто невероятно плохой и непонятный результат &ndash; сортировка записей из 5 целых чисел проходит быстрее, чем сортировка просто целых чисел! Возможно в алгоритме что-то зацикливается на выборе способа работы с маленькими по количеству и размеру элементoв данными;
<li>bubble_sort отработала достаточно быстро, её и другие медленные методы всегда можно использовать, если сортировать немного, например, до 100 элементов.
</ul>

<p>Существуют и другие методы сортировки как примитивные, так и быстрые. В библиотеке boost есть параллельные алгоритмы, позволяющие получать преимущества от наличия дополнительных процессорных ядер в системе. Можно ещё вместо std::multiset использовать самоупорядочивающийся контейнер boost::container::flat_multiset, но это работает очень медленно. Пользуюсь случаем, чтобы сказать несколько замечаний о библиотеке boost вообще. В целом, рекомендую не проходить мимо, даже те возможности, которые есть в стандартной библиотеке в boost, как правило, реализованы лучше, а иногда (как, например, регулярные выражения) значительно лучше. Если говорить о контейнерах, то в boost их заметно больше, а те, что совпадают со стандартными, несколько быстрее и имеет часто небольшие, но приятные улучшения. Boost более тщательно проверяет соответствие типов, что иногда может помочь с обнаружением почти неуловимых ошибок, которые обычно себя не проявляют, но в некоторых обстоятельствах способны неожиданно активиироваться. К недостаткам boost относиться безусловно совершенно нечитаемые и огромные по объёму сообщения об ошибках компиляции на многих конструкциях из этой библиотеки &ndash; это, хотя и в меньшей степени, относится и к стандартной библиотеке. Разработчикам С++ пора с этим уже что-то делать.

<p>Все файлы с тестами и некоторые другие смежные материалы можно взять из моего <a href=https://github.com/litwr2>репозитория</a>. Помимо сортировок, по которым приведены результаты тестов там есть и другие, например, две сортировки хэшем с бинарными деревьями вместо однонаправленных списков на ячейках хэша, сортировка массивом, варианты сортировок Шелла, быстрой и выбором. Сортировка массивом, при которой вместо хэша используется только дополнительный массив, а при коллизии элементы сдвигаются, показала себя очень плохо. Хотя если увеличить размер вспомогательного массива раза в 2, то результаты на случайных данных оказываются близкими к результатам по сортировке хэшем.

<p>Буду рад любым комментариям, критике и добавлениям.

