<head>
<meta charset=utf-8>
<title>Кратко о некоторых сортировках</title>
<meta name=keywords content="Linux Kernel,proc filesystem,system programming,sequential files,seq-file">
<style type=text/css>
pre, textarea {
    background-color: lightgreen;
}
table, th, td {
   border-width:thin;
   border-style:solid;
   border-color:green;
   border-spacing:0px;
}
</style>
</head>
<body>
<h1>И ещё о сортировках</h1>

<p>Рискну опять поднять эту тему. Начну со ссылки на статью <a href=https://habr.com/ru/post/335920/>Михаила Опанасенко (oms7)</a>, очень впечатляющую по объёмам проделанной работы, а также по количеству приведеных ссылок. Свой материал начал готовить, не зная об этой публикации, что впоследствии, после ознакомления привело к необходимости его существенной переработки. Для тех, кто уже прочитал эту статью, сообщаю, что в моём материале, исследуются более разнообразные по типам данные, в частности, строки и вещественные числа, используются библиотеки boost и bsd, а также затрагиваются некоторые другие отсутствующие там темы. 

<p>Существуют десятки различных способов расположить элементы данных по-порядку. Среди них выделяют те, что работают быстро, такие, что, например, могут она в максимум за минуты отсортировать любой массив данных, размещенный в оперативной памяти компьютера. Более конкретно можно сказать, что сортировка, работающая быстро, упорядочивает на хорошем современном персональном компьютере миллиард целых чисел за менее, чем сто секунд. Если использовать для сортировки большего числа элементов примитивные, небыстрые методы, например, пузырьковую сортировку или сортировку выбором, то время, затраченное на такую обработку данных может превзойти любые ожидания &ndash; такой "процессинг" реально может занять несколько дней. Эта большая разница вызвана тем, что время сортировки быстрыми методами занимает величину примерно пропорциональную <i>N</i>log <i>N</i>, а примитивными &ndash; <i>N</i><sup>2</sup>. С ростом <i>N</i> разница между двумя величинами становится очень заметной. Поэтому примитивные методы разумно использовать только для работ с данными небольшого объёма, например, на современных компьютерах до нескольких тысяч элементов. Их также естественно использовать для обучения азам программирования, так как они существенно проще, чем быстрые методы.

<p>Хотелось бы разобраться в существующих в нынешних стандартных библиотеках методах сортировки. Выяснить как велика разница между ними по основной характеристике, скорости работы, а также их характерные особенности. Кроме того, рассмотрим попутно для сравнения и упражнения для ума некоторые несложные в реализации методы. Стоит ещё, отметить, что оптимизатор компилятора GCC и возможно других хороших компиляторов работает с сортировками очень хорошо, ускоряя код в несколько раз (иногда даже более 5 раз).

<p>Начнём с <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%BF%D1%83%D0%B7%D1%8B%D1%80%D1%8C%D0%BA%D0%BE%D0%BC>метода пузырька</a> (bubble sort) как самого простого и медленного. По этому методу нужно раз за разом проходить по массиву данных, сравнивая соседние элементы и меняя их местами, если порядок между ними нарушен. После каждого прохода, как минимум, один элемент (наибольший или наименьший &ndash; зависит от выбранного порядка) оказывается на своём месте. Помимо простоты у этого метода есть ещё одно достоинство, он не требует дополнительной памяти. Можно отметить ещё одну особенность метода пузырька &ndash; он очень быстро обрабатывает уже упорядоченные данные и это в отдельных случаях делает его одним из самых быстрых методов. Если данные только частично упорядочены, то этот метод работает с ними быстрее, но в большинстве случаев лишь совсем незначительно. Для тестов я использовал следующую <a href=https://github.com/litwr2/research-of-sorting/blob/master/bubble.cpp>реализацию</a>.

<p>Ещё один медленный метод &ndash; сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BE%D0%BC>выбором</a> (selection sort). Здесь на каждом проходе сначала находятся наибольший и наименьший элементы в данных и затем эти элементы ставятся в соответствующие выбранному порядку крайние позиции. На следующем проходе сортируем уже данные без этих крайних элементов. Этот метод также прост как и пузырьковая сортировка и также не требует дополнительной памяти, но он заметно быстрее. Более того, сортировка по этому методу выполняет рекордно минимальное количество перестановок элементов данных. Поэтому в случае, когда перестановки значительно медленнее сравнений, упорядочение методом выбора может оказаться приемлемой, если число элементов данных невелико. Вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/selection.cpp>реализация</a>. Чаще такую сортировку реализуют, ставя на место только один элемент за проход. Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%B8%D1%80%D0%B0%D0%BC%D0%B8%D0%B4%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>кучей</a> (или пирамидальная), о которой речь пойдет далее, &ndash; это максимально продвинутый вариант рассмотриваемой сортировки. 

<p>Код для последнего рассматриваемого медленного метода, <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%81%D1%82%D0%B0%D0%B2%D0%BA%D0%B0%D0%BC%D0%B8>сортировки вставками</a> (insertion sort), наверное самый короткий среди всех кодов, реализующих сортировки, поэтому этот метод часто используют сложные быстрые сортировки для случаев, когда число сортируемых элементов мало (несколько десятков). Он чем-то похож на сортировку пузырьком, так как и тут и там последовательно сравниваются соседние элементы. Но сортировка вставками ищет для очередного элемента правильную позицию в уже отсортированной части данных, а не просто выталкивает экстремальный элемент в крайнюю позицию. При таком подходе также не нужна дополнительная память. Как и пузырьковая сортировка, сортировка вставками очень быстра на упорядоченных данных и быстрее на частично упорядоченных. В последним случае заметно быстрее пузырьковой. Обычно сортировка вставками несколько быстрее сортировки выбором. И в отличие от последней, она как и сортировка пузырьком &ndash; устойчива. Хуже всего сортировка вставками работает с данными с обратным порядком, с которыми она иногда становится самой медленной из медленных. Для тестов была использована следующая <a href=https://github.com/litwr2/research-of-sorting/blob/master/insertion.cpp>реализация</a>. Её можно немного ускорить, если использовать не линейный, а бинарный поиск, например, функцией std::bsearch. Можно ещё заметить, что это наиболее естественная сортировка &ndash; её, например, обычно интуитивно используют, играя в карты.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%A8%D0%B5%D0%BB%D0%BB%D0%B0>Шелла</a> (shell sort) является самой простой среди быстрых методов и вполне пригодной для реализации только начинающими изучать программирование учащимися. Она является лишь некоторым видоизменением пузырьковой сортировки. Разница между ними только в том, что в сортирове Шелла расстояние между сравниваемыми элементами берётся меняющимся от прохода к проходу, от большего на первом проходе, до 1 на последних, таким образом, на этих последних проходах метод Шелла вырождается в примитивную сортировку пузырьком. Дональд Шелл опубликован базовый алгоритм сортировки, получившей его имя, в 1959 году. Таким образом, это одна из первых универсальных сортировок, которые работают быстро. Для сравнения, алгоритм быстрой сортировки был опубликован спустя два года, а популярные ныне сортировка Тима или интроспективная сортировка стали известны только в 90-е. C cортировкой Шелла связаны несколько интересных нерешённых математических проблем, главная из которых &ndash; это как оптимально выбирать смещения между сравниваемыми элементами. Удалось найти некоторые рекордные последовательности, например, <a href=https://oeis.org/A102549>A102549</a>. Такие последовательности находят путем колоссальных вычислений, поэтому они имеют очень небольшую длину, A102549 &ndash; это всего 8 элементов, что хватает только для данных до примерно из 3000 элементов. Для больших данных продолжения нужно искать почти наугад. Использовал значения, близкие степеням числа 2, <i>e</i>, 2.25 и 3. Простые числа, близкие степеням 2 показали наихудшие результаты, заметно уступая лучшим. А вот остальные три варианта оказались примерно одинаковыми с точки зрения влияния на быстродействие и весьма близкими к оптимальным. Причем в этих трёх случаях использование простых чисел не давало осязаемых преимуществ. Любопытно, что смещения предлагаемые в Википедии (с основанием 2.25) на основании ссылок на соответствующие труды, не показали на тестах лучших результатов, хотя и их отличия от лучших были весьма незначительны (не более 5-10%). Использование A102549 в качестве начальной также не дало никаких заметных результатов. Михаил Опанасенко также пытался разгадать сортировку Шелла и получил очень интересный результат о том, что смещения, выбираемые по формуле <i>s<sub>n+1</sub>=10s<sub>n</sub>/3</i> (реализацию см. в коде v3), дают очень хороший эффект и возможно даже, что близкий к идеальному. Мои результаты это подтверждают. В многих случаях именно такие смещения дали наилучший результат, хотя это было и не всегда и отрыв от ближайшего результата был совсем невелик (примерно 5%).  Мой <a href=https://github.com/litwr2/research-of-sorting/blob/master/shell-tab.cpp>код</a> для реализации сортировок Шелла использует маленькие таблицы со смещениями, хотя если не использовать простые числа, то эти смещения для таблиц можно почти мгновенно вычислить, как это и сделано в реализации одного из приведенных вариантов этой сортировки.

<p>Интересно, что если брать смещения близкие степеням тройки несколько иначе и использовать несколько другой алгоритм (см. <a href=https://github.com/litwr2/research-of-sorting/blob/master/shell-plain.cpp>реализацию</a>), то на 32-битных числах будем получать скорости, близкие к лучшим, но на более длинных числах и на строках будем получать существенное замедление, иногда более, чем на 100%.

<p>Будет ли когда-нибудь найден способ находить оптимальные смещения? Возможно, но осмелюсь предположить, что ещё не скоро. Сортировка Шелла используется в ядре Linux, а в, как минимум, в одной библиотеке С её код используется для стандартной функции qsort(). Теоретически доказано, что скорость работы оптимальной сортировки Шелла по порядку лишь незначительно медленнее "настоящих" быстрых логарифмических методов. Действительно, зависимость среднего времени обработки данных от их размера для оптимальной сортировки Шелла описывается формулой &#x223d;<i>N</i>(log <i>N</i>/log log <i>N</i>)<sup>2</sup>, которая даже для весьма больших <i>N</i> весьма близка к типичной для других быстрых методов формуле &#x223d;<i>N</i>log <i>N</i>. Обычно сортировка Шелла часто даже быстрее теоретически более быстрых по порядку методов и начинает чуть уступать им лишь, при обработке довольно больших массивов (порядка 10-в миллионов элементов). Этой сортировке совершенно не нужна дополнительная память и она стабильно ведёт себя для самых разных вариантов заполнения данных, выгодно отличаясь этим от быстрых сортировок. Свойством устойчивости метод Шелла не обладает. 

<p><a href=https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>Быстрая</a> сортировка (quick sort) лишь незначительно сложнее алгоритма Шелла и до сих пор является одним из самым быстрым способом упорядочить случайно разбросанные данные. Однако у этой сортировки есть несколько недостатков. Ей требуется дополнительная память и для очень редких случаев она работает крайне медленно, по квадратичной зависимости. Главная идея этого метода в разделении данных на две части: данные в одной части должны быть больше или меньше (зависит от выбранного порядка), чем в другой. Существует несколько способов такого разделения. В идеале при каждом делении обе части должны получаться примерно одинаковыми по размеру, а хуже всего получается тогда, когда при делении одна из частей получается состоящей только из одного элемента. Рассмотрим несколько реализаций алгоритмов быстрой сортировки, в частности, <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-hoare.cpp>метод Хоара</a>, в котором опорный элемент выбирается из середины сортируемых данных.

<p>Рассмотрим также чрезвычайно компактный <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-lomuto.cpp>алгоритм Ломуто</a>, который иногда чуть (примерно на 1%) быстрее рассмотренного метода Хоара. Однако, на типовых частных случаях, например, на упорядоченных, обратных или маловариантных данных метод Ломуто показывает чрезвычайную медленность. Кроме того, среди рассмотренных вариантов быстрой сортировка эта оказалась при практических прогонах самой жадной к размеру стека: при сортировке больших массивов только этой сортировке не хватило 8 мегабайт для стека, пришлось ставить через ulimit этот размер побольше. Такая жадность к стеку приводит при обработке больших данных (десятки миллионов строк) и к существенному замедлению работы, природу которого назвать затруднюсь. Могу лишь констатировать, что с такими данными эту и сортировку из следующего абзаца лучше не использовать.

<p>Метод Ломуто в качестве опорного выбирает последний элемент, но возможно реализовать быструю сортировку вообще без <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-np.cpp>опорного элемента</a>. Такая сортировка по скоростным характеристикам оказалась близкой к методу Ломуто, хотя обычно чуть быстрее, а в экстремальных случаях &ndash; заметно быстрее Ломуто, но медленнее Хоара.

<p>В 2009 был опубликован <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-dp.cpp>алгоритм</a> быстрой сортировки с двумя опорными точками, который стал стандартным для языка Java. Этот алгоритм на 20% уменьшает число перестановок по сравнению с лучшими типовыми, но число сравнений не меняется. Его автор &ndash; Владимир Ярославский. Действительно работает, как правило, быстрее других быстрых сортировок. Я немного его оптимизировал, использовав давно известный факт, что на архитектуре x86, swap работает обычно быстрее, чем присваивание, а для строк С++ &ndash; намного-намного быстрее.  Все рассмотренные до сих пор быстрые сортировки не обладают свойством устойчивости.

<p>Дополнительная память для быстрых сортировок нужна для организации рекурсивных вызовов. Однако, второй такой вызов можно заменить на цикл, проведя оптимизацию <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D1%8F>хвостовой рекурсии</a>, которая по скорости может не дать никаких выигрышей, но существенно снижает размер используемых дополнительных данных. Я реализовал вариант сортировки Хоара с такой оптимизацией. Кроме того, в системных программах можно проверять указатель стека и если он приблизился к критическому значению, то можно просто сбросить все рекурсивные вызовы и начать сортировку заново &ndash; для этого случая очевидно, что нужно использовать вариант быстрой сортировки, не замедляющейся на почти упорядоченных данных, например, предложенный выше вариант Хоара. Борьба с использованием дополнительной памяти может считаться главной идеей быстрой сортировки из стандартной библиотеки языка С в GCC. В ней вообще отказались от рекурсии. Вместо неё используют её симуляцию, что позволяет на треть сократить нагрузку на стек. Код получился немаленький, около 150 строк. Об этой сортировке ещё будет небольшой материал ниже.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B5%D1%88-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0>хэшем</a> (hash sort) может быть очень быстрой, близкой к &#x223d;<i>N</i>. Однако, иногда она может работать и по квадратичной зависимости. Скорость работы этого метода сортировки очень зависит от входных данных. Если данные равномерно распределяются хэш-функцией по вспомогательному массиву, то получаем максимально быструю линейную зависимость. А если все данные сгуппированы возле нескольких далеко отстоящих друг "центров масс" или когда много одинаковых элементов данных, т.е. когда случается много хэш-коллизий, то получаем худшую зависимость типа &#x223d;<i>N</i><sup>2</sup>. Как и для сортировки деревом, для сортировки хэшем нужно довольно много дополнительных данных, в приводимом <a href=https://github.com/litwr2/research-of-sorting/blob/master/hash.cpp>листинге</a> кода нужно, например, 12 дополнительных байт на каждое сортируемое целое число (int32, x86-64). Интересным свойством сортировки хэшем является отсутствие операций сравнения между элементами данных, что отличает эту сортировку от всех рассмотренных выше. Точнее эти операции нужны только для случая коллизий. При сортировке данных, где ключ совпадает со всем элементом данных, можно использовать дополнительный счетчик числа одинаковых элементов, но это скорее сомнительная оптимизация. Можно ещё использовать бинарное дерево вместо списка для хранения данных хэш-коллизий, это значительно ускоряет работу для отдельных частных случаев, когда много коллизий, но в целом работа при использовании бинарного дерева во многих случаях замедляется и это при том, что в таком случае на элемент данных приходится хранить почти 100 байт дополнительной информации. Я реализовал <a href=https://github.com/litwr2/research-of-sorting/blob/master/hashtree.cpp>три варианта</a> хэш-сортировки с использованием бинарного дерева: один использует неупорядоченное дерево, а два других &ndash; стандартые деревья из библиотек std и boost. Хэш-сортировка практически непригодна для сортировки текстовых строк, за исключением совсем коротких, так как для таких данных невозможно сделать хорошую хэш-функцию. Стандартный хэш С++ (unordered_multiset) для сортировки у меня приспособить не получилось: пробовал использовать монотонные хэш-функции и упорядочивающие отношения вместо равенства &ndash; это не сработало.

<p>Сортировка массивом (array sort) очень похожа на предыдущую. Также используется вспомогательный массив, куда хэш-функцией заносятся значения. При коллизии нужно сдвинуть непрерывный фрагмент занятых элементов на позицию влево или вправо, освобождая указываемую хэш-функцией позицию для нового элемента. Для получения хорошей скорости нужно, чтобы вспомогательный массив был в несколько раз (от 2-3) больше исходного. С ростом размера вспомогательного массива скорость работы увеличивается только до некоторого предела, зависящего от сортируемых данных и связанной с ними хэш-функции, а затем (типично с 4-5) падает. Скорость работы &ndash; примерно такая же как и у хэша, но на хороших данных чуть быстрее, а на плохих &ndash; заметно медленнее. Этой сортировке также надо довольно много дополнительной памяти. Если ограничить количество элементов в сортируемом массиве числом чуть большим четырех миллиардов, то утроенный вспомогательный массив потребует столько же дополнительных данных, что и сортировка хэшем, а усемеренный &ndash; 28 байт, что заметно меньше, чем для сортировки деревом, или намного меньше, чем хэшем с деревьями. Эта сортировка также почти непригодна для работы со строками. В Википедии статьи про такой алгоритм нет, а вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/array.cpp>реализация</a>. 

<p>Интересно, что в Википедии, в хорошей обзорной <a href=https://en.wikipedia.org/wiki/Sorting_algorithm>статье</a> вообще нет упоминания таких промежуточных методов, как сортировка массивом и хэшем, которые естестественно поместить между методами, основанными на сранении элементов, и методами, основанными на абсолютном значении элементов.

<p>Одна из самых быстрых сортировок, которая вообще никогда не используют сравнений, &ndash; это известная ещё с XIX века <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%80%D0%B0%D0%B7%D1%80%D1%8F%D0%B4%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>поразрядная сортировка</a> (radix sort). Её идея очень проста &ndash; нужно работать с группами разрядов представления данных. По каждой группе строятся таблицы, а результаты потом сравнительно простым способом объединяют. Существует два основных способа использовать поразрядную сортировку. Для сортировки чисел разряды удобнее брать справа-налево (это вариант LSD &ndash; Least Significant Digit), а для сортировки строк слева-направо (это вариант MSD &ndash; Most Significant Digit). Поразрядная сортировка часто бывает значительно быстрее любых других методов упорядочения данных. Удивительно, что поддержка поразрядной сортировки до сих пор не слишком значительна: её нет ни в boost, ни в стандартной библиотеке С++, мне неизвестен даже её вариант для какой-нибудь известной библиотеки для работы с числами или строками С++. У этой сортировки есть, конечно, и недостатки. Она очень чувствительна к типу данных для сортировки, например, нужно иметь свой вариант такой сортировки для данных каждого размера, нужно делать специальный варианты для беззнаковых и знаковых целых чисел, а поддержка работы с вещественными числами может потребовать совсем немаленьких усилий. Её вариант при использовании порядка от младшего байта к старшему обычно требует дополнительной памяти, чуть большей, чем для исходных данных (это существенно меньше, чем для сортировки хэшем или массивом и тем более деревом). Кроме того, этот вариант малопригоден для сортировки длинных строк. Мой код для этой сортировки <a href=https://github.com/litwr2/research-of-sorting/blob/master/radix.cpp>здесь</a>, он основан на коде из упоминавшейся статьи oms7. Вариант с обратным порядком обработки байт более универсален и очень хорошо подходит для сортировки строк. Этот вариант можно реализовать без использования дополнительной памяти (цена этому &ndash; потеря свойства устойчивости), как это сделано в функции radixsort() библиотеки bsd. Мой <a href=https://github.com/litwr2/research-of-sorting/blob/master/radix-msd.cpp>код</a> для этого варианта также основан на коде oms7, он ценой использования дополнительной памяти, несколько большей размера исходных данных, имеет свойство устойчивости, но неоптимизирован для строк и поэтому показывает значительно худшие характеристики производительности, чем аналогичная по назначению функция sradixsort() из уже упомянутой библиотеки bsd. Эта сортировка может показать удивительно плохие результаты при работе с маленькими числовыми массивами, работая на несколько порядков медленнее, чем даже пузырьковая, хотя речь идет об очень маленьких величинах не более нескольких миллисекунд и эту разницу непросто заметить. Так получается из-за того, что она использует вспомогательные массивы небольшого размера, но при сортировке данных маленького размера эти небольшие размеры могут оказаться больше самих сортируемых данных. Для избежания замедления вариант "слева-направо" использует сортировку вставками вместо основной в таких случаеях. В заключении, стоит отметить, что это единственная известная мне относительно популярная сортировка, всегда достоверно работающая со скоростью &#x223d;<i>N</i>, но коэффициент пропорциональности здесь зависит от размеров элементов данных и для строк или длинных чисел он может быть весьма ощутим.

<p>Вариантом поразрядной сортировки MSD является сортировка <a href=https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B5%D1%84%D0%B8%D0%BA%D1%81%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE>лучом</a>, структурой данных, которая позволяет эффективно размещать ключи ассоциативного массива. Моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/trie.cpp>реализация</a>, несмотря на оптимизацию использования памяти, всё равно оказалась к ней весьма жадной. По скорости лучшие результаты получились при сортировке длинных строк.

<p>Далее рассмотрим некоторые сортировоки, которые можно встретить в стандартых библиотеках: 

<ul>
<li>быструю из стандартной библиотеки C (qsort, вариант GCC), о ней уже писал. Могу здесь только добавить, что это сортировка как и другие С-сортировки (например, следующие далее из библиотеки BSD) непригодны для работы с объектными данными, в частности, строками С++, что вызвано тем, что такие данные не являются <a href=https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85>POD</a>. Имея исходники, проблему легко решить, заменяя операции типа memcpy на обычные присваивания. Можно ещё заметить, что в некоторых стандартных библиотеках С, эта сортировка может быть не обязательно именно быстрой, её могут заменять на другие. В текущей версии для GCC эта сортировка даже обладает свойством устойчивости. С упомянутыми си-сортировками при сборе данных иногда возникали сюрпризы, они могли, например, работая с типом std::vector<int> через функциональный объект что-то в нём ломать &ndash; могу порекомендовать использовать её с даже простыми объектными данными с большой осторожностью. По данным прогонов эта сортировка иногда относительно медленная: она заметно уступает по скорости другим реализациям быстрой сортировки при работе с числами, но при работе с си-строками она лучшая, лишь сортировке с двумя опорными точками иногда получается её обогнать, но на длинных строках стандартая qsort обгоняет её почти всегда;

<li><a href=https://ru.wikipedia.org/wiki/Introsort>интроспективную</a> из стандартной библиотеки C++ (std::sort). Хотя, стоит отметить, что метод, используемый в std::sort зависит от реализации, привёл сведения только по GCC. По данным прогонов, это вторая по скорости после spread-сортировки при работе с числами, причем преимущество spread-сортировки небольшое (от почти 0 до 30%), а вот с сортировкой строк всё значительно хуже &ndash; она может уступать лидерам в 3-4 раза;

<li>устойчивую из стандартной библиотеки С++ (<a href=https://en.cppreference.com/w/cpp/algorithm/stable_sort>std::stable_sort</a>). Сортировка имеет свойство устойчивости, если она сохраняет относительный порядок между элементами с одинаковым ключом. Может использовать дополнительную память, что делает её быстрее. Удивительно, но эта сортировка нередко оказывается быстрее std::sort;

<li><a href=https://ru.wikipedia.org/wiki/Timsort>Тима</a> из <a href=https://github.com/gfx/cpp-TimSort>github-репозитория</a>, она является стандартной в языке питон. Она показывает рекордно хорошие результаты на частично-упорядоченных данных, но в среднем всё же заметно медленнее лидеров. Обычно её скорость &ndash; это среднее между быстрыми сортировками и сортировками Шелла. Обладает свойством устойчивости;

<li>поразрядную из BSD библиотеки C (<a href=https://www.freebsd.org/cgi/man.cgi?query=radixsort>radixsort</a>), там же есть устойчивый вариант этой сортировки (sradixsort). К сожалению, обе эти сортировки можно использовать только для С-строк. Как будет видно из данных по тестам &ndash; это сегодня набыстрейший способ отсортировать строки и поэтому удивительно, что нет её стандартного варианта для строк С++;

<li><a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC>слиянием</a> из BSD библиотеки C (<a href=https://linux.die.net/man/3/mergesort>mergesort</a>). Эта сортировка известна как одна из самых быстрых для данных с последовательным доступом (файлы, списки) и возможно используется в стандартной библиотеке С++ для сортировки списков (std::list и std::forward_list). Кстати, эта она известна ещё с 1948 и одним из её разработчиков был весьма небезызвестный математик и специалист по первым компьютерным системам фон Нейман. Из быстрых методов эта сортировка не выделяется лучшими характеристиками, хотя, как правило, она несколько быстрее методов Шелла. Она требует дополнительной памяти и обычно реализуется устойчивой;

<li><a href=https://ru.wikipedia.org/wiki/%D0%9A%D1%83%D1%87%D0%B0_(%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)>кучей</a> из BSD библиотеки C (heapsort). Куча обычно используется для оптимальной организации очереди с приоритетами, но может использоваться и для сортировки. Сортировки кучей не требуют дополнительной памяти, но свойством устойчивости не обладают. По скорости для чисел она значительно (до 3-6 раз) медленнее, чем методы Шелла, но для не очень коротких строк строк она показывает совсем неплохие результаты, обгоняя (с ростом длины строки преимущество растет) методы Шелла;

<li>кучей из стандартной библиотеки C++. Такая сортировка делается за две операции: построение кучи (std::make_heap) и затем собственно сортировка (<a href=https://en.cppreference.com/w/cpp/algorithm/sort_heap>std::sort_heap</a>). Здесь в отличие от библиотеки bsd сортировка &ndash; это именно одна из операций для кучи. Обычно этот вариант сортировки несколько быстрее предыдущего (вариант bsd показывает лучшие результаты только на коротких числах и длинных си-строках);

<li>бинарным сбалансированным деревом (std::multiset) &ndash; просто заполняем дерево, а затем обходим. Можно считать этот метод нерекурсивной быстрой сортировкой. Некоторая проблема возникает в том, что стандартый распределитель памяти отличается заметной неспешностью, поэтому для лучших результатов надо использовать свой распределитель, что ускоряет примерно на 10-30%. Можно ещё отметить, что такой метод требует очень много дополнительной памяти, с g++ на каждый элемент данных, помимо него самого нужно ещё хранить 32 байтa (на архитектуре x86-64). Если использовать boost::container::multiset, памяти нужно поменьше: только дополнительных 24 байта на элемент данных. Однако как boost, так и стандартная библиотека продемонстрировали один неприятный сюрприз &ndash; в процессе работы они иногда требовали больше памяти, чем было необходимо. Возможно это из-за балансировки бинарных деревьев. Коды &ndash; <a href=https://github.com/litwr2/research-of-sorting/blob/master/tree.cpp>здесь</a>;

<li><a href=https://en.wikipedia.org/wiki/Spreadsort>spreadsort</a> из библиотеки boost, изобретенный уже в 21 веке, наиболее быстрый в целом на сегодня алгоритм из присутствующих в известных библиотеках. Эта сортировка использует некоторые идеи поразрядной и подобно ей может быть довольно капризной к типу аргументов. Обычно это сортировка показывает рекордные результаты, иногда существенно лучшие тех, что у ближайших конкурентов. Единственное исключение &ndash; это сортировка С-строк, где она существенно уступает поразрядным методам из библиотеки bsd. При сортировке длинных С-строк она может уступать и другим методам, например, spin-сортировке или быстрой сортировке с двумя опорными точками. У spread-сортировки (boost v1.62) обнаружилась очень неприятная проблема &mdash; при сортировке небольших (до 1000 элементов) массивов С-строк она работает с ошибками;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/pdqsort.html>pdqsort</a> из библиотеки boost, новый алгоритм, улучшающий, как заявлено автором, интроспективную сортировку. Это новый алгоритм, который пока ещё не описан в Википедии. Его результаты &ndash; хотя и неплохие, но не особо впечатляющие. Он медленнее std::sort на коротких целых, но быстрее на строках и длинных целых. В обоих случаях разница скорее незначительная. Лучшие результаты у этой сортировки получились для длинных С++-строк &ndash; здесь она уступает, хотя и заметно, только лидеру spread-сортировке; 

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/spinsort.html>spinsort</a> из библиотеки boost. Это также новый устойчивый алгоритм, который ещё не описан в Википедии. Обычно он близок к лидеру, но с заметным отставанием от него;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/flat_stable_sort.html>flat_stable_sort</a> из библиотеки boost. Это ещё один новый устойчивый алгоритм, который пока не описан в Википедии. Это безусловно быстрый метод, но несколько уступающий большинству других быстрых библиотечных методов. Он использует очень мало дополнительной памяти;

<p>Рассмотрим таблицу времени (в мс) работы этих алгоритмов на компьютере с 8 ГБ оперативной памяти с процессором AMD Phenom&#x2122; II X4 955 @3.214 МГц. Компьютер работал в общей сложности несколько месяцев. Тайминги приводятся по среднему от числа прогонов, для меньшего размера данных прогонов было больше. Многие современные процессоры работают, переключаясь между разными частотами, а работа с кэшем довольно сложным образом меняет скорость вычислений, поэтому полученные результаты в лучшем случае только приблизительны (могу предполагать, что неточности таймингов могут доходить до 20%). Полагаю, что на лучших современных процессорах для ПК результат может быть получен в 2-3 раза быстрее.

<div align=center>
<iframe src=table1.html height=180% width=80% style="border:2px solid blue"></iframe>
</div>

<p>Некоторые общие выводы по результатам этой таблицы:
<ul>
<li>лучшие shell-сортировки на данных размером до 10 миллионов элементов могут обгонять timsort и даже некоторые быстрые сортировки;
<li>timsort очень близка по скорости qsort (clib), иногда несколько обгоняя, а иногда наоборот отставая;
<li>heapsort и особенно treesort часто заметно тормозят, но на фоне bubblesort или даже selectionsort видно, что это всё-таки быстрые методы. Интересно, что оба этих метода нередко имеют весьма близкие характеристики &ndash; они оба строят деревья. Легко заметить, что у heapsort и treesort зависимости хотя и явно не квадратичные, но очевидно и не <i>N</i>log <i>N</i>, а существенно хуже &ndash; сравните с сортировкой Шелла, которая с ростом объёма данных ведёт себя гораздо лучше, чем heapsort или treesort, при том, что она сама медленнее, чем <i>N</i>log <i>N</i>. Таким образом, практические реализации heapsort и std::multiset не соответствуют их теоретическим спецификациям;;
<li>данные по сортировкам строк показывают, что законы временных зависимостей здесь не такие как для чисел &ndash; на эти законы здесь как-то накладываются длины строк, которые сортируются. Мне, к моему сожалению, неизвестны формулы для известных сортировок, которые бы давали точные законы временных зависимостей при работе со строками;
<li>hash_sort показала совершено посредственные результаты, это возможно из-за того, что из-за использования дополнительной памяти резко падает эффективность работы кэшей процессора. На небольших случайных данных (менее ста тысяч элементов) сортировка хэшем обгоняет лучшие быстрые (qsort) сортировки. Можно ещё заметить, что возможно опять из-за кешей, некоторые результаты у этой сортировки очень странные, например, 10<sup>5</sup>, 10<sup>6</sup> и 10<sup>7</sup> 32-разрядных целых при использовании ordered random заполнения сортируются за примерно одно и то же время! Какие-то почти квантовые эффекты. :) Уверен, что если поискать, то можно найти и другие труднообъяснимые результаты.
</ul>

<p>Добавлю ещё некоторые выводы по некоторым частным случаям:
<ul>
<li>некоторые типы заполнения данных обнаруживают слабые места быстрых сортировок. Однако выбор опорного элемента сложным образом делает вероятность попадания на плохую для сортировки последовательность практически нулевой. Можно также выбирать опорный элемент на каждом проходе по разному или случайно. Возможно так и делают в qsort (clib). Рассматриваемый метод Хоара работает медленно только на специально сконструированных последовательностях, встретить которые случайно при практической работе &ndash; это случай с вероятностью 2<sup><i>N</i>-3</sup>/<i>N</i><sup><i>N</i></sup>, то есть почти абсолютно невозможное событие. Также почти невозможно случайно получить данный, на которых быстрая сортировка с двумя опорными точками, будет работать медленно, по квадратичному закону. Варианты быстрых сортировок Ломуто и без опорного элемента показывают очень плохие результаты почти на всех частных случаях заполнений;
<li>на некоторых частных случаях, самая медленная "пузырьковая" сортировка даёт отличные результаты, а одни из самых быстрых, quick-сортировки, наоборот очень плохие;
<li>сортировка хэшем показала очень плохой результат на заполнениях типа VIII и IX, это объясняется тем, что монотонная последовательность берётся из последовательных величин, начиная с меньшего, а 1% случайных числел берётся из диапазона от меньшего до максимального значения, что скучивает все последовательные 99% данных в один элемент хэша. Этот случай очень хорошо демонстрирует проблемы, которые могут возникнуть при использовании этой сортировки с неизвестными данными;
<li>сортировка выбором ведёт себя очень стабильно на всех типах заполнения, heap- и tree-сортировки также довольно стабильны, без явных пиков и провалов. Это верно, конечно, и для сортировок Шелла, а также большинства других быстрых методов из стандартных библиотек.
</ul>

<p>Теперь пора рассказать об типах данных, использованных с сортировочными алгоритмами:

<ol type=I>
<li>целые числа, 32-битные знаковые (int32_t), но использовались только неотрицательные. Другие числовые данные также брались только неотрицательные &ndash; это не снижает общности полученных результатов, но делает их получение для некоторых алгоритмов существенно проще;
<li>целые числа, 64-битные знаковые (int64_t);
<li>целые числа, 128-битные знаковые (__int128 &ndash; поддерживаются, как минимум, GCC);
<li>пять целых чисел (int32_t), одно из которых используется как ключ (INT1P4). При сортировке таких данных более существенно на время вычислений начинает влиять количество перестановок, поэтому методы с меньшим числом перестановок получают некоторое преимущество;
<li>вещественные числа типа double;
<li>короткие строки C++ и С. Брались строки длиной от 1 до 16, что даёт средней длину строки равной 8.5 (strings short и c-strings short);
<li>строки С и С++ средней длины, длина которых от 1 до 256, что даёт средней длину строки равной 128.5 (strings и c-strings);
<li>длинные строки С и С++, длина которых от 1 до 2<sup>20</sup> (это чуть больше миллиона), причем строки подбираются так, что их средняя длина не превосходит 512, &ndash; так подбирались строки только для случайного заполнения, для остальных случаев брались строки длиной от 1 до 512 (strings long и c-strings long).
</ol>


<p>А также о способах заполнения исходного массива для сортировки:

<ol type=I>
<li>случайно;
<li>строго по возрастанию (упорядоченные, ordered);
<li>строго по убыванию (обратного порядка, reversed);
<li>случайные величины из диапазона от 0 до 99 (малого разброса, low variation 100);
<li>случайная последовательность из 0 и 1 (малого разброса, low variation 2);
<li>константой 0 (малого разброса, low variation 1);
<li>последовательность, приводящая приведёный вариант qsort (Hoare) к самому медленному исполнению. Любопытно, что таких последовательностей ровно 2<sup><i>N</i>-3</sup> среди всех последовательностей длины <i>N</i>;
<li>строго по возрастанию, с вставкой 1% случайных чисел (ordered_random);
<li>строго по убыванию, с вставкой 1% случайных величин (reversed_random).
</ol>

<p>Следует подчеркнуть, что случайные данные (random) &ndash; это самый типичный случай заполнения массива, все остальные способы &ndash; это крайне редкие и даже почти невозможные при нормальной работе частности.

<p>Рассмотрим ещё результаты тестов, где сортировки работают со всеми возможными последовательностями данных. Число таких последовательностей равно факториалу от их длины, таким образом, для последовательностей длины 12 существует 479'001'600 вариантов &ndash; такое их количество хороший современный ПК обсчитает за менее, чем минуту. Если мы возьмём последовательности длины 14, то получим уже 87'178'291'200 вариантов на несколько часов работы компьютера. Поэтому в следующей таблице &ndash; среднее время (в тактах процессора, получаемых через инструкцию RDTSC) одной сортировки при сортировке всех перестановок длиной только до 12. В качестве данных берутся прежние числовые типы и короткие строки. Конечно, можно было заметить, что последовательности с повторяющимися элементами не рассматриваются. Однако, осмелюсь предположить, что их наличие качественно не изменило бы результатов, но могло существенно замедлить их получение.

<div align=center>
<iframe src=table2.html height=120% width=80% style="border:2px solid blue"></iframe>
</div>

<p>Очевидно, что результаты по таким маленьким данным не слишком репрезентативны и особенно по сложным методам сортировки, но некоторое представление о поведении сортировок они всё-таки дополняют. Некоторые сортировки, насколько мне известно, заменяют свой основной алгоритм на другой при работе с маленькими массивами &ndash; это сортировки spread, radix_msd (последняя использует вставки). А некоторые сортировки (flat_stable и radix) используют маленькие таблицы, но при крошечных размерах данных эти таблицы оказываются гораздо большими самих данных, что сильно тормозит эти методы на фоне других и производит странные результаты. Странные результаты также получаются и у других поразрядных сортировок и у сортировок хэшем и массивом. Такие необычные результаты легко объясняются тем, что время подготовки данных перед сортировкой у этих методов для маленьких данных больше времени самой сортировки. Конечно, при измерении таких маленьких временных интервалов (наносекунды) влияние неточности данных на выводимый закон гораздо выше, чем в предыдущей таблице. Поэтому законы получились очень приблизительные, часто "с заносом" к преувеличенным значениям. Последнее частично объясняется тем, что при работе с маленькими данными время собственно сортировки становится сравнимым с временем вызова функции сортировки и нескольких необходимых вспомогательных операций по замеру времени. Программа старается вычесть названные накладные расходы из выводимого результата, но это получается делать скорее очень приблизительно. При всём этом осмелюсь ещё предположить, что, сравнивая результаты для разных типов данных и принимая в расчет сделанные замечания, можно делать иногда предположения, не очень далёкие от точных.
<br>

<p>В заключении ещё одна таблица, которая показывает насколько много требуется разным тестируемым методам сортировки дополнительной памяти. Очевидно, эта величина зависит от системы. В моих тестах, как уже писал, это x86-64, GCC. Буква Т в ней означает размер типа в байтах (в этот размер длина строки не входит: для си-строк &ndash; это размер указателя, для строк си++ &ndash; это размер дескриптора, 32 байта для x86-64 GCC), буква L &ndash; средняя длина типа в байтах (для чисел это равно Т, а для строк это средняя длина строки), буква А может иметь значение 1 или 0 &ndash; это выравнивание до 64-битной границы, а буква M &ndash; это выравнивание от стандартного распределителя памяти (оно предположительно выравнивает на 32-байтную границу). Значок <sup>*</sup> означает, что данные по этому типу сортировки были получены только на основании анализа чтения поля VmRSS из /proc/PID/status (упомянутое поле &ndash; это размер программы-процесса).

<div align=center>
<table>
<tr><th>Метод<th>Зависимость<tr><td>array*1<td align=center>(T + 1/8)<i>N</i>
<tr><td>array*k, k&gt;1<td align=center>(T + 4k)<i>N</i>
<tr><td>bubble<td align=center>0
<tr><td>clib_qsort<td align=center>от &#x2248;T<i>N</i>/2 до &#x2248;T<i>N</i><sup>*</sup>
<tr><td>flat_stable<td align=center>&#x2248;T<i>N</i>/256
<tr><td>hash<td align=center>(T + 8 + 4A)<i>N</i>
<tr><td>hashbt<td align=center>(T + 12)<i>N</i>
<tr><td>hashbt_boost<td align=center>(56 + T + 4A + M)<i>N</i>
<tr><td>hashbt_std<td align=center>(80 + T + 4A + M)<i>N</i>
<tr><td>heapsort<td align=center>0
<tr><td>insertion<td align=center>0
<tr><td>mergesort_bsd<td align=center>от &#x2248;Tlog<sub>2</sub><i>N</i> до T<i>N</i><sup>*</sup>
<tr><td>pdq<td align=center>Tlog<i>N</i>
<tr><td>quicksort<td align=center>от &#x2248;16log<sub>2</sub><i>N</i> до 16<i>N</i>
<tr><td>quicksort_tco<td align=center>от 0 до <i>N</i>
<tr><td>radix<td align=center>&#x2248;T<i>N</i>
<tr><td>radix8_trie<td align=center>от &#x2248;T<i>N</i> + 24L до &#x2248;(T + 24L + 12)<i>N</i>
<tr><td>radix_bsd<td align=center>0
<tr><td>radix_msd<td align=center>&#x2248;T<i>N</i>
<tr><td>selection<td align=center>0
<tr><td>shell<td align=center>0
<tr><td>spin<td align=center>T<i>N</i>/2
<tr><td>spread<td align=center>&#x2248;0
<tr><td>sradix_bsd<td align=center>&#x2248;T<i>N</i><sup>*</sup>
<tr><td>stlsort<td align=center>от 0 до до &#x2248;Tlog<sub>2</sub><i>N</i><sup>*</sup>
<tr><td>stlstable<td align=center>от 0 до &#x2248;T<i>N</i>/2<sup>*</sup>
<tr><td>timsort<td align=center>от 0 до &#x2248;T<i>N</i><sup>*</sup>
<tr><td>tree_boost<td align=center>(T + 24)<i>N</i>
<tr><td>tree_stl<td align=center>(T + 32)<i>N</i>
</table>
</div>

<p>Существуют и другие методы сортировки как примитивные, так и быстрые. В библиотеке boost есть параллельные алгоритмы, позволяющие получать преимущества от наличия дополнительных процессорных ядер в системе. Можно ещё вместо std::multiset использовать самоупорядочивающийся контейнер boost::container::flat_multiset, но это работает очень медленно.

<p>Пользуюсь случаем, чтобы сказать несколько замечаний о библиотеке boost вообще. В целом рекомендую не проходить мимо. Даже те возможности, которые есть в стандартной библиотеке, в boost, как правило, реализованы лучше, а иногда (как, например, регулярные выражения) значительно лучше. Если говорить о контейнерах, то в boost их заметно больше, а те, что совпадают со стандартными, иногда несколько быстрее и имеют часто небольшие, но приятные улучшения. Boost более тщательно проверяет соответствие типов, что иногда может помочь с обнаружением почти неуловимых ошибок, которые обычно себя не проявляют, но в некоторых обстоятельствах способны неожиданно активироваться. К недостаткам boost относиться безусловно совершенно нечитаемые и огромные по объёму сообщения об ошибках компиляции на многих конструкциях из этой библиотеки &ndash; это, хотя и в меньшей степени, относится и к стандартной библиотеке. Разработчикам С++ пора с этим уже что-то делать.

<p>Кстати, говоря о библиотеках, добавлю, что во Free BSD у стандартных для этой среды <a href=https://www.freebsd.org/cgi/man.cgi?query=mergesort>сортировок</a> появились некоторые дополнительные возможности, в частности, для поддержки мультитредности.

<p>Все файлы с тестами и некоторые другие смежные материалы можно взять из моего <a href=https://github.com/litwr2/research-of-sorting>репозитория</a>. Буду рад любым комментариям, критике и добавлениям.

