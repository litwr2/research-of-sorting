<head>
<meta charset=utf-8>
<title>Кратко о некоторых сортировках</title>
<meta name=keywords content="Linux Kernel,proc filesystem,system programming,sequential files,seq-file">
<style type=text/css>
pre, textarea {
    background-color: lightgreen;
}
table, th, td {
   border-width:thin;
   border-style:solid;
   border-color:green;
   border-spacing:0px;
}
</style>
</head>
<body>
<h1>Кратко о некоторых сортировках</h1>

<p>Рискну опять поднять эту тему. Начну со ссылки на статью Михаила Опанасенко (oms7) <a href=https://habr.com/ru/post/335920/>Описание алгоритмов сортировки и сравнение их производительности</a>, очень впечатляющую по объёмам проделанной работы, а также по количеству приведеных ссылок. Свой материал начал готовить, не зная об этой публикации, что впоследствии, после ознакомления привело к необходимости его существенной переработки. Для тех, кто уже прочитал эту статью, сообщаю, что в моём материале, исследуются более разнообразные по типам данные, в частности, строки и вещественные числа, используются библиотеки boost и bsd, а также затрагиваются некоторые другие отсутствующие в статье Михаила темы. 

<p>Существуют десятки различных способов расположить элементы данных по-порядку. Среди них выделяют те, что работают быстро, такие, что, например, могут она в максимум за минуты отсортировать любой массив данных, размещенный в оперативной памяти компьютера. Более конкретно можно сказать, что сортировка, работающая быстро, упорядочивает на хорошем современном персональном компьютере миллиард целых чисел за менее, чем сто секунд. Если использовать для сортировки большего числа элементов примитивные, небыстрые методы, например, пузырьковую сортировку или сортировку выбором, то время, затраченное на такую обработку данных может превзойти любые ожидания &ndash; такой "процессинг" реально может занять несколько дней. Эта большая разница вызвана тем, что время сортировки быстрыми методами занимает величину примерно пропорциональную <i>N</i>log <i>N</i>, а примитивными &ndash; <i>N</i><sup>2</sup>. С ростом <i>N</i> разница между двумя величинами становится очень заметной. Поэтому примитивные методы разумно использовать только для работ с данными небольшого объёма, например, до нескольких тысяч элементов на современных компьютерах. Их также естественно использовать для обучения азам программирования, так как они существенно проще, чем быстрые методы.

<p>Хотелось бы разобраться в существующих в нынешних стандартных библиотеках методах сортировки. Выяснить как велика разница между ними по основной характеристике, скорости работы, а также их характерные особенности. Кроме того, рассмотрим попутно для сравнения и упражнения для ума некоторые несложные в реализации методы. Стоит ещё, отметить, что оптимизатор компилятора GCC и возможно других хороших компиляторов работает с сортировками очень хорошо, ускоряя код в несколько раз (иногда даже более 5 раз).

<p>Начнём с <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%BF%D1%83%D0%B7%D1%8B%D1%80%D1%8C%D0%BA%D0%BE%D0%BC>метода пузырька</a> (bubble sort) как самого простого и медленного. По этому методу нужно раз за разом проходить по массиву данных, сравнивая соседние элементы и меняя их местами, если порядок между ними нарушен. После каждого прохода, как минимум, один элемент (наибольший или наименьший &ndash; зависит от выбранного порядка) оказывается на своём месте. Помимо простоты у этого метода есть ещё одно достоинство, он не требует дополнительной памяти. Можно отметить ещё одну особенность метода пузырька &ndash; он очень быстро обрабатывает уже упорядоченные данные и это в отдельных случаях делает его одним из самых быстрых методов. Если данные только частично упорядочены, то этот метод работает с ними быстрее, но в большинстве случаев лишь совсем незначительно. Для тестов я использовал следующую <a href=https://github.com/litwr2/research-of-sorting/blob/master/bubble.cpp>реализацию</a>.

<p>Ещё один медленный метод &ndash; сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BE%D0%BC>выбором</a> (selection sort). Здесь на каждом проходе сначала находятся наибольший и наименьший элементы в данных и затем эти элементы ставятся в соответствующие выбранному порядку крайние позиции. На следующем проходе сортируем уже данные без этих крайних элементов. Этот метод также прост как и пузырьковая сортировка и также не требует дополнительной памяти, но он заметно быстрее. Более того, сортировка по этому методу выполняет рекордно минимальное количество перестановок элементов данных. Поэтому в случае, когда перестановки значительно медленнее сравнений, упорядочение методом выбора может оказаться приемлемой, если число элементов данных невелико. Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%B8%D1%80%D0%B0%D0%BC%D0%B8%D0%B4%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>кучей</a> (или пирамидальная), о которой речь пойдет далее, &ndash; это максимально продвинутый вариант рассмотриваемой сортировки. Вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/selection.cpp>реализация</a>. Чаще такую сортировку реализуют, ставя на место только один элемент за проход.

<p>Код для последнего рассматриваемого медленного метода, <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%81%D1%82%D0%B0%D0%B2%D0%BA%D0%B0%D0%BC%D0%B8>сортировки вставками</a> (insertion sort), наверное самый короткий среди всех кодов, реализующих сортировки, поэтому этот метод часто используют сложные быстрые сортировки для случаев, когда число сортируемых элементов мало (несколько десятков). Он чем-то похож на сортировку пузырьком, так как и тут и там последовательно сравниваются соседние элементы. Но сортировка вставками ищет для очередного элемента правильную позицию в уже отсортированной части данных, а не просто выталкивает экстремальный элемент в крайнюю позицию. При таком подходе также не нужна дополнительная память. Как и пузырьковая сортировка, сортировка вставками очень быстра на упорядоченных данных и быстрее на частично упорядоченных. В последним случае заметно быстрее пузырьковой. Обычно сортировка вставками несколько быстрее сортировки выбором. И в отличие от последней, она как и сортировка пузырьком &ndash; устойчива. Хуже всего сортировка вставками работает с данными с обратным порядком, с которыми она иногда становится самой медленной из медленных. Для тестов была использована следующая <a href=https://github.com/litwr2/research-of-sorting/blob/master/insertion.cpp>реализация</a>. Её можно немного ускорить, если использовать не линейный, а бинарный поиск, например, функцией std::bsearch. Можно ещё заметить, что это наиболее естественная сортировка &ndash; её, например, обычно интуитивно используют, играя в карты.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%A8%D0%B5%D0%BB%D0%BB%D0%B0>Шелла</a> (shell sort) является самой простой среди быстрых методов и вполне пригодной для реализации только начинающими изучать программирование учащимися. Она является лишь некоторым видоизменением пузырьковой сортировки. Разница между ними только в том, что в сортирове Шелла расстояние между сравниваемыми элементами берётся меняющимся от прохода к проходу, от большего на первом проходе, до 1 на последних, таким образом, на этих последних проходах метод Шелла вырождается в примитивную сортировку пузырьком. Дональд Шелл опубликован базовый алгоритм сортировки, получившей его имя, в 1959 году. Таким образом, это одна из первых универсальных сортировок, которые работают быстро. Для сравнения, алгоритм быстрой сортировки был опубликован спустя два года, а популярные ныне сортировка Тима или интроспективная сортировка стали известны только в 90-е. Cортировка Шелла до сих пор является довольно плохо теоретически изученной: с ней связано несколько интересных нерешённых математических проблем, главная из которых &ndash; это как оптимально выбирать смещения между сравниваемыми элементами. Обнаружились некоторые рекордные последовательности, например, <a href=https://oeis.org/A102549>A102549</a>. Такие последовательности находят путем колоссальных вычислений, поэтому они имеют очень небольшую длину, A102549 &ndash; это всего 8 элементов, что хватает только для данных до примерно из 3000 элементов. Для больших данных продолжения нужно искать почти наугад. Использовал значения, близкие степеням числа 2, e, 2.25 и 3. Простые числа, близкие степеням 2 показали наихудшие результаты, заметно уступая лучшим. А вот остальные три варианта оказались примерно одинаковыми с точки зрения влияния на быстродействие и весьма близкими к оптимальным. Причем в этих трёх случаях использование простых чисел не давало осязаемых преимуществ. Любопытно, что смещения предлагаемые в Википедии (с основанием 2.25) на основании ссылок на соответствующие труды, не показали на тестах лучших результатов, хотя и их отличия от лучших были весьма незначительны (не более 5-10%). Использование A102549 в качестве начальной также не дало никаких заметных результатов. Михаил Опанасенко также пытался разгадать сортировку Шелла и получил очень интересный результат о том, что смещения, выбираемые по формуле <i>s<sub>n+1</sub>=10s<sub>n</sub>/3</i> (реализацию см. в коде v3), дают очень хороший эффект и возможно даже, что близкий к идеальному. Мои результаты это подтверждают. В многих случаях именно такие смещения дали наилучший результат, хотя это было и не всегда и отрыв от ближайшего результата был совсем невелик (примерно 5%). Интересно, что если брать смещения близкие степеням тройки несколько иначе и использовать несколько другой алгоритм (реализацию см. в коде v3), то на числах будем получать примерно те же скорости, близкие к лучшим, а иногда даже и чутьт лучшие, но на строках будем получать существенное замедление, иногда более чем на 100%. Будет ли когда-нибудь найден способ находить оптимальные смещения? Возможно, но осмелюсь предположить, что ещё не скоро. Сортировка Шелла используется в ядре Linux, а в, как минимум, в одной библиотеке С её код используется для стандартной функции qsort(). Теоретически доказано, что скорость работы оптимальной сортировки Шелла по порядку лишь незначительно медленнее "настоящих" быстрых логарифмических методов. Действительно, зависимость среднего времени обработки данных от их размера для оптимальной сортировки Шелла описывается формулой &#x223d;<i>N</i>(log <i>N</i>/log log <i>N</i>)<sup>2</sup>, которая даже для весьма больших <i>N</i> весьма близка к типичной для других быстрых методов формуле &#x223d;<i>N</i>log <i>N</i>. Практически обычно сортировка Шелла часто даже быстрее теоретически более быстрых по порядку методов и начинает чуть уступать им лишь, при обработке довольно больших массивов (порядка 10-в миллионов элементов). Этой сортировке не нужна дополнительная память и она стабильно ведёт себя для самых разных вариантов заполнения данных, выгодно отличаясь этим от быстрых сортировок. Свойством устойчивости метод Шелла не обладает. 

<p><a href=https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>Быстрая</a> сортировка (quick sort) лишь незначительно сложнее алгоритма Шелла и до сих пор является одним из самым быстрым способом упорядочить случайно разбросанные данные. Однако у этой сортировки есть несколько недостатков. Ей требуется дополнительная память и для очень редких случаев она работает крайне медленно, по квадратичной зависимости. Главная идея этого метода в разделении данных на две части: данные в одной части должны быть больше или меньше (зависит от выбранного порядка), чем в другой. Существует несколько способов такого разделения. В идеале при каждом делении обе части должны получаться примерно одинаковыми по размеру, а хуже всего получается тогда, когда при делении одна из частей получается состоящей только из одного элемента. Рассмотрим несколько реализаций алгоритмов быстрой сортировки, в частности, <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-hoare.cpp>метод Хоара</a>, в котором опорный элемент выбирается из середины сортируемых данных. Все быстрые сортировки не обладают свойством устойчивости.

<p>Рассмотрим также чрезвычайно компактный <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-lomuto.cpp>алгоритм Ломуто</a>, который в среднем чуть быстрее рассмотренного метода Хоара. Однако, на типовых частных случаях, например, на упорядоченных, обратных или маловариантных данных метод Ломуто показывает чрезвычайную медленность. Кроме того, среди рассмотренных вариантов быстрой сортировка эта оказалась при практических прогонах самой жадной к размеру стека: при сортировке 100 миллионов случайных С++ строк только этой сортировке не хватило 8 мегабайт для стека, пришлось ставить через ulimit этот размер побольше. Такая жадность к стеку приводит при обработке больших данных (десятки миллионов строк) и к существенному замедлению работы, природу которого назвать затруднюсь. Могу лишь констатировать, что с такими данными эту и сортировку из следующего абзаца лучше не использовать.

<p>Метод Ломуто в качестве опорного выбирает последний элемент, но возможно реализовать быструю сортировку вообще без <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-np.cpp>опорного элемента</a>. Такая сортировка по скоростным характеристикам оказалась близкой к методу Ломуто, хотя в среднем и чуть быстрее, а в экстремальных случаях &ndash; заметно быстрее Ломуто, но медленнее Хоара.

<p>В 2009 был опубликован <a href=https://github.com/litwr2/research-of-sorting/blob/master/quick-dp.cpp>алгоритм</a> быстрой сортировки с двумя опорными точками, который стал стандартным для языка Java. Этот алгоритм на 20% уменьшает число перестановок по сравнению с лучшими типовыми, но число сравнений не меняется. Его автор &ndash; Владимир Ярославский. Действительно работает, как правило, быстрее других быстрых сортировок. Немного его оптимизировал, использовав давно известный факт, что на архитектуре x86, swap работает обычно быстрее, чем присваивание, а для строк С++ &ndash; намного-намного быстрее.

<p>Дополнительная память для быстрых сортировок нужна для организации рекурсивных вызовов. Однако, второй такой вызов можно заменить на цикл, проведя оптимизацию <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D1%8F>хвостовой рекурсии</a>, которая по скорости может не дать никаких выигрышей, но существенно снижает размер используемых дополнительных данных (для большего эффекта, согласно Седгевику, нужно делать рекурсивный вызов только для большей части данных). Кроме того, в системных программах можно проверять указатель стека и если он приблизился к критическому значению, то можно просто сбросить все рекурсивные вызовы и начать сортировку заново &ndash; для этого случая очевидно, что нужно использовать вариант быстрой сортировки, не замедляющейся на почти упорядоченных данных, например, предложенный выше вариант Хоара. Борьба с использованием дополнительной памяти может считаться главной идеей быстрой сортировки из стандартной библиотеки языка С в GCC. В ней вообще отказались от рекурсии! Вместо неё используют её симуляцию, что позволяет на треть сократить нагрузку на стек. Код получился немаленький, около 150 строк. Об этой сортировке ещё будет небольшой материал ниже.

<p>Сортировка <a href=https://ru.wikipedia.org/wiki/%D0%A5%D0%B5%D1%88-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0>хэшем</a> (hash sort) может быть очень быстрой, близкой к &#x223d;<i>N</i>. Однако, иногда она может работать и по квадратичной зависимости. Скорость работы этого метода сортировки очень зависит от входных данных. Если данные равномерно распределяются хэш-функцией по вспомогательному массиву, то получаем максимально быструю линейную зависимость. А если все данные сгуппированы возле нескольких далеко отстоящих друг "центров масс" или когда много одинаковых элементов данных, т.е. когда случается много хэш-коллизий, то получаем худшую зависимость типа &#x223d;<i>N</i><sup>2</sup>. Как и для сортировки деревом, для сортировки хэшем нужно довольно много дополнительных данных, в приводимом <a href=https://github.com/litwr2/research-of-sorting/blob/master/hash.cpp>листинге</a> кода нужно 12 дополнительных байт на каждый сортируемый элемент данных. Интересным свойством сортировки хэшем является отсутствие операций сравнения между элементами данных, что отличает эту сортировку от всех рассмотренных выше. Точнее эти операции нужны только для случая коллизий. При сортировке данных, где ключ совпадает со всем элементом данных, можно использовать дополнительный счетчик числа одинаковых элементов, но это это очень сомнительная оптимизация. Можно ещё использовать бинарное дерево вместо списка для хранения данных хэш-коллизий, это значительно ускоряет работу для отдельных частных случаев, когда много коллизий, но в целом работа при использовании бинарного дерева во многих случаях замедляется и это при том, что в таком случае на элемент данных приходится хранить почти 100 байт дополнительной информации. Хэш-сортировка практически непригодна для сортировки текстовых строк, за исключением совсем коротких, так как для таких данных невозможно сделать хорошую хэш-функцию. Стандартный хэш С++ (unordered_multiset) для сортировки у меня приспособить не получилось: пробовал использовать монотонные хэш-функции и упорядочивающие отношения вместо равенства &ndash; это не сработало.

<p>Сортировка массивом (array sort) очень похожа на предыдущую. Также используется вспомогательный массив, куда хэш-функцией заносятся значения. При коллизии нужно сдвинуть непрерывный фрагмент занятых элементов на позицию влево или вправо, освобождая указываемую хэш-функцией позицию для нового элемента. Для получения хорошей скорости нужно, чтобы вспомогательный массив был в несколько раз (от 2-3) больше исходного. С ростом размера вспомогательного массива скорость работы увеличивается только до некоторого предела, зависящего от сортируемых данных и связанной с ними хэш-функции, а затем (типично с 4-5) падает. Скорость работы &ndash; примерно такая же как и у хэша, но хороших данных чуть быстрее, а на плохих &ndash; заметно медленнее. Этой сортировке также надо довольно много дополнительной памяти. Если ограничить количество элементов в сортируемом массиве числом чуть большим четырех миллиардов, то утроенный вспомогательный массив потребует столько же дополнительных данных, что и сортировка хэшем, а усемеренный &ndash; 28 байт, что заметно меньше, чем для сортировки деревом, или намного меньше, чем хэшем с деревьями. Эта сортировка также почти непригодна для работы со строками. В Википедии статьи про такой алгоритм нет, а вот моя <a href=https://github.com/litwr2/research-of-sorting/blob/master/array.cpp>реализация</a>. Интересно, что в Википедии, в хорошей обзорной <a href=https://en.wikipedia.org/wiki/Sorting_algorithm>статье</a> вообще нет упоминания таких промежуточных методов, как сортировка массивом и хэшем, которые естестественно поместить между методами, основанными на сранении элементов, и методами, основанными на абсолютном значении элементов.

<p>Одна из самых быстрых сортировок, которая вообще никогда не используют сравнений, &ndash; это известная ещё с XIX века <a href=https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%80%D0%B0%D0%B7%D1%80%D1%8F%D0%B4%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0>поразрядная сортировка</a> (radix sort). Её идея очень проста &ndash; нужно работать с группами разрядов представления данных. По каждой группе строятся таблицы, а результаты потом сравнительно простым способом объединяют. Существует два основных способа использовать поразрядную сортировку. Для сортировки чисел разряды удобнее брать справа-налево, а для сортировки строк слева-направо. Поразрядная сортировка часто бывает значительно быстрее любых других методов упорядочения данных. Удивительно, что поддержка поразрядной сортировки до сих пор не слишком значительна: её нет ни в boost, ни в стандартной библиотеке С++, мне неизвестен даже её вариант для какой-нибудь известной библиотеки для работы с числами или строками С++. У этой сортировки есть, конечно, и недостатки. Она очень чувствительна к типу данных для сортировки, например, нужно иметь свой вариант такой сортировки для данных каждого размера, нужно делать специальный варианты для беззнаковых и знаковых целых чисел, а поддержка работы с вещественными числами может потребовать совсем немаленьких усилий. Её вариант при использовании порядка от младшего байта к старшему обычно требует дополнительной памяти, чуть большей, чем для исходных данных (это существенно меньше, чем для сортировки хэшем или массивом и тем более деревом). Кроме того, этот вариант малопригоден для сортировки длинных строк. Мой код для этой сортировки <a href=https://github.com/litwr2/research-of-sorting/blob/master/radix.cpp>здесь</a>, он основан на коде из упоминавшейся статьи oms7. Вариант с обратным порядком обработки байт более универсален и очень хорошо подходит для сортировки строк. Этого вариант можно реализовать без использования дополнительной памяти (цена этому &ndash; потеря свойства устойчивости), как это сделано в функции radixsort() библиотеки bsd. Мой <a href=https://github.com/litwr2/research-of-sorting/blob/master/radix-msd.cpp>код</a> для этого варианта также основан на коде oms7, он ценой использования дополнительной памяти, несколько большей размера исходных данных, имеет свойство устойчивости, но неоптимизирован для строк и поэтому показывает значительно худшие характеристики производительности, чем аналогичная по назначению функция sradixsort() из уже упомянутой библиотеки bsd. Эта сортировка может показать удивительно плохие результаты при работе с маленькими числовыми массивами, работая на несколько порядков медленнее, чем даже пузырьковая, хотя речь идет о величинах не более нескольких миллисекунд и эту разницу непросто заметить. Это случается из-за того, что она использует вспомогательные массивы небольшого размера, но при сортировке данных маленького размера эти небольшие размеры могут оказаться больше самих сортируемых данных. Для избежания замедления вариант "слева-направо" использует сортировку вставками вместо основной в таких случаеях. В заключении, стоит отметить, что это единственная известная мне относительно популярная сортировка, всегда достоверно работающая со скоростью &#x223d;<i>N</i>, но коэффициент пропорциональности здесь зависит от размера элемента данных и для строк он может быть весьма велик.

<p>Далее рассмотрим некоторые сортировоки, которые можно встретить в стандартых библиотеках: 

<ul>
<li>быструю из стандартной библиотеки C (qsort), о ней уже писал. Могу здесь только добавить, что это сортировка как и другие С-сортировки (например, следующие далее из библиотеки BSD) непригодны для работы с объектными данными, в частности, строками С++, что вызвано тем, что такие данные не являются <a href=https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85>POD</a>. Имея исходники, проблему легко решить, заменяя операции типа memcpy на обычные присваивания. Можно ещё заметить, что в некоторых стандартных библиотеках С, эта сортировка может быть не обязательно именно быстрой, её могут заменять на другие. В текущей версии для GCC эта сортировка даже обладает свойством устойчивости. С упомянутыми си-сортировками при сборе данных ещё иногда возникали сюрпризы, они могли, например, работая с типом std::vector<int> через функциональный объект что-то в нём ломать &ndash; могу порекомендовать использовать её с даже простыми объектными данными с большой осторожностью;

<li><a href=https://ru.wikipedia.org/wiki/Introsort>интроспективную</a> из стандартной библиотеки C++ (std::sort). Хотя, стоит отметить, что метод, используемый в std::sort зависит от реализации, привёл сведения только по GCC;

<li>устойчивую из стандартной библиотеки С++ (<a href=https://en.cppreference.com/w/cpp/algorithm/stable_sort>std::stable_sort</a>). Сортировка имеет свойство устойчивости, если она сохраняет относительный порядок между элементами с одинаковым ключом. Может использовать дополнительную память, что делает её быстрее;

<li><a href=https://ru.wikipedia.org/wiki/Timsort>Тима</a> из <a href=https://github.com/gfx/cpp-TimSort>github-репозитория</a>, она является стандартной в языке питон. Она показывает рекордно хорошие результаты на частично-упорядоченных данных, но в среднем всё же заметно медленнее лидеров. Обладает свойством устойчивости;

<li>поразрядная из BSD библиотеки C (radixsort), там же есть устойчивый вариант этой сортировки (sradixsort). К сожалению, обе эти сортировки можно использовать только для С-строк. Как будет видно из данных по тестам &ndash; это сегодня набыстрейший способ отсортировать строки и поэтому удивительно, что нет её варианта стандартного для строк С++;

<li><a href=https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC>слиянием</a> из BSD библиотеки C (mergesort). Эта сортировка известна как одна из самых быстрых для данных с последовательным доступом (файлы, списки) и возможно используется в стандартной библиотеке С++ для сортировки списков (std::list и std::forward_list). Кстати, эта она известна ещё с 1948 и одним из её разработчиков был весьма небезызвестный математик и специалист по первым компьютерным системам фон Нейман;

<li><a href=https://ru.wikipedia.org/wiki/%D0%9A%D1%83%D1%87%D0%B0_(%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)>кучей</a> из BSD библиотеки C (heapsort). Куча обычно используется для оптимальной организации очереди с приоритетами, но может использоваться и для сортировки;

<li>кучей из стандартной библиотеки C++. Такая сортировка делается за две операции: построение кучи (std::make_heap) и затем собственно сортировка (std::sort_heap). Здесь в отличие от библиотеки bsd сортировка &ndash; это именно одна из операций для кучи;

<li>бинарным сбалансированным деревом (std::multiset) &ndash; просто заполняем дерево, а затем обходим. Можно считать этот метод нерекурсивной быстрой сортировкой. Некоторая проблема возникает в том, что стандартый распределитель памяти отличается заметной неспешностью, поэтому для лучших результатов надо использовать свой распределитель, что ускоряет примерно на 10-30%. Можно ещё отметить, что такой метод требует очень много дополнительной памяти, с g++ на каждый элемент данных, помимо него самого нужно ещё хранить 32 байтa (на архитектуре x86-64). Если использовать boost::container::multiset, памяти нужно поменьше: только дополнительных 24 байта на элемент данных. Однако как boost так и стандартная библиотека продемонстрировали один неприятный сюрприз &ndash; в процессе работы они иногда требовали существенно (до 100%) больше памяти, чем было необходимо. Возможно это из-за балансировки бинарных деревьев. Коды &ndash; <a href=https://github.com/litwr2/research-of-sorting/blob/master/tree.cpp>здесь</a>;

<li><a href=https://en.wikipedia.org/wiki/Spreadsort>spreadsort</a> из библиотеки boost, изобретенный уже в 21 веке, наиболее быстрый в целом на сегодня алгоритм из присутствующих в известных библиотеках. Эта сортировка использует некоторые идеи поразрядной и подобно ей может быть довольно капризной к типу аргументов. Только поразрядная сортировка может сегодня обогнать более универсальную spreadsort &ndash; за большую универсальность, как это обычно бывает, пришлось заплатить иногда весьма заметным замедлением работы. У этой сортировки (boost v1.62) обнаружилась очень неприятная проблема &mdash; при сортировке небольших (до 1000 элементов) массивов С-строк она работает с ошибками;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/pdqsort.html>pdqsort</a> из библиотеки boost, новый алгоритм, сочетающий в себе, как заявлено автором, лучшие черты быстрой сортировки и сортировки кучей. Это новый алгоритм, который пока ещё не описан в Википедии; 

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/spinsort.html>spinsort</a> из библиотеки boost. Это также новый алгоритм, который ещё не описан в Википедии;

<li><a href=https://www.boost.org/doc/libs/1_70_0/libs/sort/doc/html/sort/single_thread/flat_stable_sort.html>flat_stable_sort</a> из библиотеки boost. Это ещё один новый алгоритм, который пока не описан в Википедии;

<p>Соберём основные сведения об этих сортировках в следующую таблицу. Красным выделены предполагаемые величины, их реальное значение может быть другим.

<div align=center>
<table border=1>
<tr><th rowspan=2>Алгоритм<th colspan=3>Время работы<th rowspan=2>Устойчивость<th rowspan=2>Дополнительная<br>память
<tr><th>наилучшее<th>среднее<th>наихудшее
<tr><td>radix<td colspan=3 align=center>&#x223d;<i>N</i><td align=center>***<td align=right>&#x223d;<i>N</i>
<tr><td>shell<td align=center>&#x223d;<i>N</i>log <i>N</i><td colspan=2 align=center>&#x223d;<i>N</i>(log <i>N</i>/log log <i>N</i>)<sup>2</sup><td align=center rowspan=3>нет<td align=right>0
<tr><td>quick<td colspan=2 align=center>&#x223d;<i>N</i>log <i>N</i><td align=center>&#x223d;<i>N</i><sup>2</sup><td align=right>&#x223d;log <i>N</i>*
<tr><td>std::sort<td colspan=3 align=center>&#x223d;<i>N</i>log <i>N</i><td align=right>&#x223d;log <i>N</i>
<tr><td>std::stable_sort<td colspan=2 align=center>&#x223d;<i>N</i>log <i>N</i><td align=center>&#x223d;<i>N</i>(log <i>N</i>)<sup>2</sup><td rowspan=2 align=center>еcть<td align=right>от 0 до <i>N</i>**
<tr><td>tim<td align=center rowspan=8>&#x223d;<i>N</i><td colspan=2 rowspan=5 align=center>&#x223d;<i>N</i>log <i>N</i><td align=right><i>N</i>
<tr><td>spread<td rowspan=2 align=center>нет<td align=right style=color:red>&#x223d;log <i>N</i>
<tr><td>pdq<td align=right>&#x223d;log <i>N</i>
<tr><td>spin<td rowspan=2 align=center>есть<td align=right><i>N</i>/2
<tr><td>flat_stable<td align=right><i>N</i>/256 + 8KB
<tr><td>hash<td align=center style=color:red rowspan=2>&#x223d;<i>N</i>log <i>N</i><td align=center rowspan=2>&#x223d;<i>N</i><sup>2</sup><td rowspan=5 align=center>нет<td align=right rowspan=2>&#x223d;<i>N</i>
<tr><td>array
<tr><td>bubble<td colspan=2 align=center>&#x223d;<i>N</i><sup>2</sup><td align=right rowspan=2>0
<tr><td>heap<td colspan=3 rowspan=3 align=center>&#x223d;<i>N</i>log <i>N</i>
<tr><td>tree<td align=right>&#x223d;<i>N</i>
<tr><td>merge<td align=center>***<td align=right><i>N</i>
<tr><td>selection<td colspan=3 align=center>&#x223d;<i>N</i><sup>2</sup><td align=center rowspan=4>нет<td align=right>0
</table>
<p>* &ndash; при использовании оптимизации хвостовой рекурсии по методу, предложенному Седгевиком (Sedgewick).
<p>** &ndash; при наличие дополнительной памяти производительность повышается.
<p>*** &ndash; зависит от реализации.
</div>

<p>Рассмотрим таблицу времени (в мс) работы этих алгоритмов на массиве случайных целых чисел (32-битных) на компьютере с 8 ГБ оперативной памяти с процессором AMD Phenom&#x2122; II X4 955 @3.214 МГц. Компьютер работал в общей сложности несколько месяцев! Тайминги приводятся по среднему от числа прогонов, для меньшего размера данных прогонов было больше. Многие современные процессоры работают, переключаясь между разными частотами, а работа с кэшем довольно сложным образом меняет скорость вычислений, поэтому полученные результаты в лучшем случае только приблизительны (могу предполагать, что неточности таймингов могут доходить до 20%). На лучших современных процессорах для ПК результат может быть получен в 2-3 раза быстрее.


<p>Теперь пора рассказать об типах данных, использованных с сортировочными алгоритмами:

<ol type=I>
<li>целые числа, 32-битные знаковые (int32_t), но использовались только неотрицательные. Другие числовые данные также брались только неотрицательные &ndash; это не снижает общности полученных результатов, но делает их получение для некоторых алгоритмов существенно проще;
<li>целые числа, 64-битные знаковые (int64_t);
<li>целые числа, 128-битные знаковые (__int128 &ndash; поддерживаются, как минимум, GCC);
<li>пять целых чисел (int32_t), одно из которых используется как ключ (record 5);
<li>вещественные числа типа double;
<li>короткие строки C++ и С. Брались строки длиной от 1 до 16, что даёт средней длину строки равной 8.5 (strings short и c-strings short);
<li>строки С и С++ средней длины, длина которых от 1 до 256, что даёт средней длину строки равной 128.5 (strings medium и c-strings medium);
<li>длинные строки С и С++, длина которых от 1 до 2<sup>20</sup> (это чуть больше миллиона), причем строки подбираются так, что их средняя длина не превосходит 512 (strings long и c-strings long).
</ol>


<p>А также о способах заполнения исходного массива для сортировки:

<ol type=I>
<li>случайно;
<li>строго по возрастанию (упорядоченные, ordered);
<li>строго по убыванию (обратного порядка, reversed);
<li>случайные числа из диапазона от 0 до 99 (малого разброса, low variation 100);
<li>случайная последовательность из 0 и 1 (малого разброса, low variation 2);
<li>константой 0 (малого разброса, low variation 1);
<li>последовательность, приводящая приведёный вариант qsort (Hoare) к самому медленному исполнению. Любопытно, что таких последовательностей ровно 2<sup><i>N</i>-3</sup> среди всех последовательностей длины <i>N</i>;
<li>строго по возрастанию, с вставкой 1% случайных чисел (ordered_random);
<li>строго по убыванию, с вставкой 1% случайных величин (reversed_random).
</ol>

<p>Следует подчеркнуть, что случайные данные (random) &ndash; это самый типичный случай заполнения массива, все остальные способы &ndash; это крайне редкие и даже почти невозможные при нормальной работе частности.

<div align=center>
<iframe src=table1.html height=452 width=615 scrolling=no style=border:none></iframe>
<p align=center>* &ndash; выведенное из формул, приблизительное значение
</div>

<p>Некоторые выводы по результатам этой таблицы:
<ul>
<li>стандартная сортировка библиотеки C (GCC) относительно медленная, она заметно уступает по скорости другим реализациям быстрой сортировки при работе с числами, но при работе с си-строками она &ndash; лучшая, лишь сортировке с двумя опорными точками иногда получается её обогнать, но на длинных строках стандартая qsort обгоняет её почти всегда;
<li>std::stable_sort очень быстрая и (сюрприз!) значительно обгоняет даже назначенную быть более быстрой, неустойчивую std::sort;
<li>shellsort (e) на данных размером от 10 миллионов элементов и менее обгоняет timsort и даже некоторые быстрые сортировки;
<li>pdqsort работает несколько медленнее, чем и std::sort, что противоречит его заявленным свойствам;
<li>timsort уступала по скорости qsort (clib) вплоть до массива с миллиардом элементов, но на нём, как наверное и на больших данных, становится чуть быстрее;
<li>heapsort и особенно treesort заметно тормозят, но на фоне bubblesort или даже selectionsort видно, что это всё-таки быстрые методы. Интересно, что std::sort_heap на небольших данных обгоняет heapsort из BSD, но с ростом размера данных теряет преимущество и начинает уступать;
<li>hash_sort показала совершено посредственные результаты, это из-за того, что из-за использования дополнительной памяти резко падает эффективность работы кэшей процессора. На небольших случайных данных (менее ста тысяч элементов) сортировка хэшем обгоняет лучшие быстрые (qsort) сортировки;
<li>легко заметить, что у heapsort и treesort зависимости хотя и явно не квадратичные, но очевидно и не <i>N</i>log <i>N</i>, а существенно хуже &ndash; сравните с сортировкой Шелла, которая с ростом объёма данных ведёт себя гораздо лучше, чем heapsort или treesort, при том, что она сама медленнее, чем <i>N</i>log <i>N</i>. Таким образом, практические реализации heapsort и std::multiset не соответствуют их теоретическим спецификациям.
</ul>

<p>Рассмотрим ещё таблицу времени (в мс) работы этих же алгоритмов на массиве записей, состоящих из пяти целых чисел, из которых одно используется как ключ. Тайминги опять приводятся по среднему от пяти прогонов. При сортировке таких данных более существенно на время вычислений начинает влиять количество перестановок, поэтому методы с меньшим числом перестановок получают некоторое преимущество, которое растет с ростом размера данных, не используемых как ключ. 

<div align=center>
<iframe src=table2.html height=452 width=600 scrolling=no style=border:none></iframe>
<p align=center>* &ndash; выведенное из формулы, приблизительное значение
</div>

<p>Из результатов в этой таблице также можно сделать несколько выводов:
<ul>
<li>std::stable_sort при работе с такими данными показывает значительно худшую производительность;
<li>hash_sort обгоняет shellsort, но очевидно, что с небольшим приращением к объёму данных, shellsort станет быстрее, что показывает, что динамика скорости у сортировки хэшем существенно хуже логарифмической;
<li>интересно, что heapsort (bsd) и treesort на таких данных ведут себя практически идентично;
<li>qsort (Hoare) становится самой быстрой среди быстрых сортировок;
<li>pdqsort чуть обогнала на таких данных std::sort.
</ul>

<p>Рассмотрим теперь производительность сортировок на разного рода редких, крайних случаях. Используем массив целых чисел из 100 тысяч элементов, брать больше миллиона для таких тестов не рекомендую. Используются следующие типы заполнения:
<ol type=I>
<li>строго по возрастанию;
<li>строго по убыванию;
<li>случайные числа из диапазона от 0 до 99;
<li>случайная последовательность из 0 и 1;
<li>константой 0;
<li>последовательность, приводящая приведёный вариант qsort (Hoare) к самому медленному исполнению. Любопытно, что таких последовательностей ровно 2<sup><i>N</i>-3</sup> среди всех последовательностей длины <i>N</i>;
<li>строго по возрастанию, с вставкой 1% случайных чисел.
</ol>

<div align=center>
<iframe src=table3.html height=462 width=440 scrolling=no style=border:none></iframe>
</div>

<p>По этим результатам мои выводы следующие:
<ul>
<li>эти тесты обнаруживают слабые места быстрых сортировок. Однако выбор опорного элемента сложным образом делает вероятность попадания на плохую для сортировки последовательность практически нулевой. Можно также выбирать опорный элемент на каждом проходе по разному, случайно. Возможно так и делают в qsort (clib). Рассматриваемый метод Хоара работает медленно только на специально сконструированных последовательностях, встретить которую случайно при практической работе &ndash; это случай с вероятностью 2<sup><i>N</i>-3</sup>/<i>N</i><sup><i>N</i></sup>, то есть почти абсолютно невозможное событие. Варианты быстрых сортировок Ломуто и без опорного элемента показывают довольно плохие результаты как на частичично упорядоченных данных, так и на данных с маленьким разбросом значений;
<li>на некоторых частных случаях, самая медленная "пузырьковая" сортировка даёт отличные результаты, а самые быстрые qsort наоборот очень плохие;
<li>сортировка хэшем показала очень плохой результат на заполнении типа VII, это объясняется тем, что последовательность по возрастанию берётся из последовательных чисел, начиная с 0, а случайные числа из 1% берутся из диапазона от 0 до RAND_MAX, что скучивает все последовательные 99% данных в один элемент хэша. Этот случай очень хорошо демонстрирует проблемы, которые могут возникнуть при использовании этой сортировки с неизвестными данными;
<li>сортировка выбором ведёт себя очень стабильно на всех типах заполнения, heapsort и treesort также довольно стабильны, без явных пиков и провалов;
<li>поразительно плохой результат qsort (Lamuto) на заполнении типа VII был для меня неожиданностью. 
</ul>

<p>И в заключении рассмотрим результаты теста, где сортировки работают со всеми возможными последовательностями данных.  Число таких последовательностей равно факториалу от их длины, таким образом, для последовательностей длины 12 существует 479'001'600 вариантов &ndash; такое их количество хороший современный ПК обсчитает за менее, чем минуту. Если мы возьмём последовательности длины 14, то получим уже 87'178'291'200 вариантов на несколько часов работы компьютера. Поэтому в следующей таблице &ndash; среднее время (в тактах процессора, получаемых через инструкцию RDTSC) одной сортировки при сортировке всех перестановок длиной только 12. В качестве данных берутся прежние числовые типы и короткие строки. Конечно, результаты по таким маленьким данным не слишком репрезентативны и особенно по сложным методам сортировки, но некоторое представление о поведении сортировок они всё-таки дополняют. 
<br><br>

<div align=center>
<table border=1>
<tr><th rowspan=2>Ранг<th rowspan=2>Алгоритм<th colspan=2>Тайминги<th rowspan=2>Ранг
<tr><td align=right>4 байта<td align=right>4+16 байт
<tr><td align=center>7<td>shell (e)<td align=right>157<td align=right>220<td align=right>9
<tr><td align=center>14<td>qsort (clib)<td align=right>287<td align=right>434<td align=right>15
<tr><td align=center>11<td>qsort (Hoare)<td align=right>182<td align=right>196<td align=right>6
<tr><td align=center>8<td>qsort (no pivot)<td align=right>158<td align=right>204<td align=right>7
<tr><td align=center>6<td>qsort (Lomuto)<td align=right>154<td align=right>215<td align=right>8
<tr><td align=center>1<td>std::sort<td align=right>116<td align=right>165<td align=right>4
<tr><td align=center>10<td>std::stable_sort<td align=right>173<td align=right>289<td align=right>12
<tr><td align=center>9<td>timsort<td align=right>167<td align=right>236<td align=right>10
<tr><td align=center>17<td>heapsort (bsd)<td align=right>629<td align=right>1848<td align=right>17
<tr><td align=center>13<td>heapsort<td align=right>257<td align=right>370<td align=right>13
<tr><td align=center>4<td>spreadsort<td align=right>123<td align=right>155<td align=right>1
<tr><td align=center>2<td>pdqsort<td align=right>117<td align=right>156<td align=right>2
<tr><td align=center>3<td>spinsort<td align=right>119<td align=right>163<td align=right>3
<tr><td align=center>18<td>flat_stable_sort<td align=right>2239<td align=right>1165<td align=right>18
<tr><td align=center>15<td>hash_sort<td align=right>319<td align=right>446<td align=right>16
<tr><td align=center>16<td>tree_sort<td align=right>404<td align=right>432<td align=right>14
<tr><td align=center>12<td>bubble_sort<td align=right>194<td align=right>252<td align=right>11
<tr><td align=center>5<td>selection_sort<td align=right>151<td align=right>175<td align=right>5
</table>
</div>
<br>

<p>По последним результатам у меня получилось всего два комментария:
<ul>
<li>как и почти обычно heapsort выделяется своей неспешностью, а flat_stable_sort показала просто невероятно плохой и непонятный результат &ndash; сортировка записей из 5 целых чисел проходит быстрее, чем сортировка просто целых чисел! Возможно в алгоритме что-то зацикливается на выборе способа работы с маленькими по количеству и размеру элементoв данными;
<li>bubble_sort отработала достаточно быстро, её и другие медленные методы всегда можно использовать, если сортировать немного, например, до 100 элементов.
</ul>

<p>Существуют и другие методы сортировки как примитивные, так и быстрые. В библиотеке boost есть параллельные алгоритмы, позволяющие получать преимущества от наличия дополнительных процессорных ядер в системе. Можно ещё вместо std::multiset использовать самоупорядочивающийся контейнер boost::container::flat_multiset, но это работает очень медленно. Пользуюсь случаем, чтобы сказать несколько замечаний о библиотеке boost вообще. В целом, рекомендую не проходить мимо, даже те возможности, которые есть в стандартной библиотеке в boost, как правило, реализованы лучше, а иногда (как, например, регулярные выражения) значительно лучше. Если говорить о контейнерах, то в boost их заметно больше, а те, что совпадают со стандартными, несколько быстрее и имеет часто небольшие, но приятные улучшения. Boost более тщательно проверяет соответствие типов, что иногда может помочь с обнаружением почти неуловимых ошибок, которые обычно себя не проявляют, но в некоторых обстоятельствах способны неожиданно активиироваться. К недостаткам boost относиться безусловно совершенно нечитаемые и огромные по объёму сообщения об ошибках компиляции на многих конструкциях из этой библиотеки &ndash; это, хотя и в меньшей степени, относится и к стандартной библиотеке. Разработчикам С++ пора с этим уже что-то делать.

<p>Все файлы с тестами и некоторые другие смежные материалы можно взять из моего <a href=https://github.com/litwr2>репозитория</a>. Помимо сортировок, по которым приведены результаты тестов там есть и другие, например, две сортировки хэшем с бинарными деревьями вместо однонаправленных списков на ячейках хэша, сортировка массивом, варианты сортировок Шелла, быстрой и выбором. Сортировка массивом, при которой вместо хэша используется только дополнительный массив, а при коллизии элементы сдвигаются, показала себя очень плохо. Хотя если увеличить размер вспомогательного массива раза в 2, то результаты на случайных данных оказываются близкими к результатам по сортировке хэшем.

<p>Буду рад любым комментариям, критике и добавлениям.

std::string_view
